{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e3ce5f2c",
   "metadata": {},
   "source": [
    "method1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sampling strategy', SMOTE(random_state=3)),\n",
    "    ('classifier', DummyClassifier(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "method2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sampling strategy', SMOTE(random_state=3)),\n",
    "    ('classifier', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0cae4d",
   "metadata": {},
   "source": [
    "##### Investigating data types and transforming feature, refercencing the article :\n",
    "https://medium.com/vickdata/four-feature-types-and-how-to-transform-them-for-machine-learning-8693e1c24e80"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5c19b21",
   "metadata": {},
   "source": [
    "def quick_analysis(df):\n",
    "    \"\"\"\n",
    "    function from reference\n",
    "    \n",
    "    purpose : investigate data types and null values of data frame\n",
    "    \"\"\"\n",
    "    print(\"Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"Rows and Columns:\")\n",
    "    print(df.shape)\n",
    "    print(\"Column Names:\")\n",
    "    print(df.columns)\n",
    "    print(\"Null Values:\")\n",
    "    print(df.apply(lambda x: sum(x.isnull()) / len(df)))\n",
    "    \n",
    "# quick_analysis(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530e35f",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb85ba93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.968842Z",
     "start_time": "2021-01-06T21:00:38.944800Z"
    }
   },
   "source": [
    "# create bins for 'AGE'\n",
    "\n",
    "\n",
    "df_train['AGE'] = pd.cut(df_train.AGE,\n",
    "                              bins=[20,40,60,100],\n",
    "                              labels=[1,2,3])\n",
    "\n",
    "df_train.rename({'AGE':'AGE_BIN'},axis=1, inplace = True)\n",
    "\n",
    "# df_train['AGE'] = df_train['AGE_BIN']\n",
    "# df_train.rename({'AGE':'AGE_BIN'}, inplace = True)\n",
    "\n",
    "# # # drop 'AGE'\n",
    "# df_train.drop(['AGE'], axis=1, inplace=True)\n",
    "\n",
    "# # inspect\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bec533db",
   "metadata": {},
   "source": [
    "df_train.AGE_BIN.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913b89d",
   "metadata": {},
   "source": [
    "may introduce a skew - probably not a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d921ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9078ab14",
   "metadata": {},
   "source": [
    "### Pipeline transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54547e0a",
   "metadata": {},
   "source": [
    "def AgeBinner(df): \n",
    "    \"\"\"\n",
    "    bins age and changes feature name from 'AGE' to 'AGE_BIN'\n",
    "    \n",
    "    the use of this causes much information loss : https://stats.stackexchange.com/questions/68834/what-is-the-benefit-of-breaking-up-a-continuous-predictor-variable\n",
    "    \"\"\"\n",
    "    df['AGE'] = pd.cut(df_train.AGE,\n",
    "                              bins=[20,40,60,100],\n",
    "                              labels=[1,2,3])\n",
    "    df.rename({'AGE':'AGE_BIN'},axis=1, inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def HarschCleaner(df):\n",
    "    \"\"\"\n",
    "    Cleaner that does :\n",
    "        outlier normalization (fit outlier into the input range)\n",
    "    \"\"\"\n",
    "    return \n",
    "\n",
    "    \n",
    "def Cleaner(df): \n",
    "    \"\"\"\n",
    "    Cleaner that does : \n",
    "        no age binning\n",
    "        outlier nor\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dbce315",
   "metadata": {},
   "source": [
    "def SMOTE_sampler(df, random_state = 3, show_plot=False, **kwargs):\n",
    "    \"\"\"\n",
    "    https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "    \n",
    "    Synethtic minority oversampling technique\n",
    "        Use : to make the ML model more robust in minority predictions (which may be one of the keys)\n",
    "    \n",
    "    Param:\n",
    "        df  : dataframe to be oversampled\n",
    "        **kwargs : additional SMOTE arguement\n",
    "    \n",
    "    Returns oversampled df\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state, kwargs)\n",
    "    X, y = df[features], df['DEFAULT']\n",
    "    \n",
    "    df_new = smote.fit_resample(X,y) \n",
    "    \n",
    "    if(show_plot):\n",
    "        pd.value_counts(df['DEFAULT']).plot.bar()\n",
    "        plt.title('Class Imbalance Before Oversampling')\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Number of Clients\")\n",
    "        plt.show()\n",
    "        \n",
    "#         pd.value_counts(df_new['DEFAULT']).plot.bar()\n",
    "#         plt.title('Class Imbalance After Oversampling')\n",
    "#         plt.xlabel(\"Class\")\n",
    "#         plt.ylabel(\"Number of Clients\")\n",
    "#         plt.show()\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1974f0",
   "metadata": {},
   "source": [
    "### Pipelines ideas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ff1ab22",
   "metadata": {},
   "source": [
    "class Pipeline2(Pipeline):\n",
    "    \"\"\"\n",
    "    sklearn pipeline class that can also return transformed (pipelined) data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,steps):\n",
    "        Pipeline.__init__(self, steps)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Applies all transforms to the data, without applying last \n",
    "       estimator. from : https://stackoverflow.com/questions/33469633/how-to-transform-items-using-sklearn-pipeline\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            Data to predict on. Must fulfill input requirements of first step of\n",
    "            the pipeline.\n",
    "        \"\"\"\n",
    "        Xt = X\n",
    "        for name, transform in self.steps[:-1]:\n",
    "            Xt = transform.transform(Xt)\n",
    "        return Xt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f576dd8a",
   "metadata": {},
   "source": [
    "method1 = Pipeline([\n",
    "    ('cleaning', HarshCleaner),\n",
    "    ('feature transformer', transforms feature)\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sampling strategy', SMOTE_sampler())\n",
    "    ('ML model', )\n",
    "])\n",
    "\n",
    "# comment : shouldn't work with df but with the X_train and X_test\n",
    "methodX.fit_transform(X_train)\n",
    "# methodX.transform(X_test) % this step is included in the Pipeline.predict(data) command. Scaler are applied during the transform step of predict (inplicit), not fitted again. \n",
    "methodX.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8777447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f56653a",
   "metadata": {},
   "source": [
    "### Sampling strategy : Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e36fcf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:43.927973Z",
     "start_time": "2021-01-06T21:00:43.796295Z"
    }
   },
   "source": [
    "# plot class imbalance\n",
    "pd.value_counts(df_train['DEFAULT']).plot.bar()\n",
    "plt.title('Class Imbalance')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "214bc101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:46.560203Z",
     "start_time": "2021-01-06T21:00:43.929761Z"
    }
   },
   "source": [
    "# set data\n",
    "X = df_train[features]\n",
    "y = df_train['DEFAULT']\n",
    "\n",
    "# simple oversampling with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "df_train_smote, df_train_smote['DEFAULT'] = smote.fit_resample(X, y)\n",
    "\n",
    "# hybrid resampling SMOTETomek\n",
    "smt = SMOTETomek(random_state=42)\n",
    "df_train_smt, df_train_smt['DEFAULT'] = smt.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6197d42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:46.657574Z",
     "start_time": "2021-01-06T21:00:46.561708Z"
    },
    "scrolled": true
   },
   "source": [
    "# plot results with SMOTE\n",
    "pd.value_counts(df_train_smote['DEFAULT']).plot.bar()\n",
    "plt.title('Class Imbalance')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "485752a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:46.767601Z",
     "start_time": "2021-01-06T21:00:46.659938Z"
    }
   },
   "source": [
    "# plot results with SMOTETomek\n",
    "pd.value_counts(df_train_smt['DEFAULT']).plot.bar()\n",
    "plt.title('Class Imbalance')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a6041f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:46.779004Z",
     "start_time": "2021-01-06T21:00:46.771037Z"
    }
   },
   "source": [
    "# we select the SMOTE-Tomek data to move forward\n",
    "df_train = df_train_smt.copy()\n",
    "y_train = df_train_smt['DEFAULT']\n",
    "X_train = df_train_smt[features]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fcc0041",
   "metadata": {},
   "source": [
    "df_train_smt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaeee88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ffaf80",
   "metadata": {},
   "source": [
    "### Data set transformation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "315de8fc",
   "metadata": {},
   "source": [
    "# this dataset can be changed for whatever after feature selection\n",
    "\n",
    "# split X, y\n",
    "# X_train, y_train = df_train.iloc[:,:-1], df_train.iloc[:,-1:]   # #not necessary yet\n",
    "X_test, y_test = df_test.iloc[:,:-1], df_test.iloc[:,-1:]\n",
    "\n",
    "# reshape y into 1d column vector\n",
    "y_train, y_test = np.reshape(y_train, (y_train.shape[0],)), np.reshape(y_test, (y_test.shape[0],))\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "\n",
    "# # unravel labels for SVM\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
