{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YW9A454mpxiM"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250622,
     "status": "ok",
     "timestamp": 1610128594503,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "JAsI0yL9pz9j",
    "outputId": "f9adc7de-3781-40b1-c519-e4674b496d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Archive:  /content/drive/MyDrive/DataFiles.zip\n",
      "  inflating: CreditCard_test.csv     \n",
      "  inflating: CreditCard_train.csv    \n"
     ]
    }
   ],
   "source": [
    "# use google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# unzip local files\n",
    "!unzip /content/drive/MyDrive/DataFiles.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvU--O9zp1SD"
   },
   "outputs": [],
   "source": [
    "# load data from local colab machine\n",
    "train = '/content/CreditCard_train.csv'\n",
    "test = '/content/CreditCard_test.csv'\n",
    "\n",
    "train_dataset = pd.read_csv(train, index_col=0, header=1)\n",
    "test_dataset = pd.read_csv(test, index_col=0, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CfoqR1Vp2L9"
   },
   "outputs": [],
   "source": [
    "# this dataset can be changed for whatever after feautre selection\n",
    "\n",
    "# split X, y\n",
    "X_train, y_train = train_dataset.iloc[:,:-1], train_dataset.iloc[:,-1:]\n",
    "X_test, y_test = test_dataset.iloc[:,:-1], test_dataset.iloc[:,-1:]\n",
    "\n",
    "# reshape y into 1d column vector\n",
    "y_train, y_test = np.reshape(y_train, (y_train.shape[0],)), np.reshape(y_test, (y_test.shape[0],))\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "# y_train = preprocessing.scale(y_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "# y_test = preprocessing.scale(y_test)\n",
    "\n",
    "\n",
    "# # unravel labels for SVM\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfYMF36uRqdT"
   },
   "source": [
    "#Motivation:\n",
    "\n",
    "In the larger scope of ML algorithms, we've now determinted that the most appropriate model for our situation is the SVM. \n",
    "\n",
    "However, these models have many intricacies  that vastly change their preformance and usabilty, thus, we will further our model selection to pick the most appropriate parameters for our model.\n",
    "\n",
    "For this, we will take a \"Darwinist\" approach. By testing all these parameteres seperatly against a \"baseline\" SVM model (as defined by sklearn), and picking the best preforming one, we should be able to hypothetically create the \"best\" model for out dataset. However, there are some rammifications of not testing certain parameters together, which we will detail and talk about.\n",
    "\n",
    "The SVM parameters we are evaulation are as such:\n",
    "\n",
    "*  The type of kernel\n",
    "*  The degree for polynomial kernels\n",
    "*  The gamma kernel coefficent\n",
    "* The shrinking heuristic\n",
    "* The strength of the regularization parameter\n",
    "\n",
    "\n",
    "However, it is also worth nothing that we won't experiment with some parameters. For example, we will be using the same tolerance for stoping criterion (1e-3) as we want to keep the bound on the relative error of our models comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRy8j8kp0VCr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function used to evaluate different SVM models\n",
    "def evalModel(model, model_name, verbose = False):\n",
    "  # every model is evaluated against the same test dataset\n",
    "\n",
    "  # use the model passed as a parameter to make predictions, which we will use to judge the model \n",
    "  predicted = model.predict(X_test)\n",
    "\n",
    "  # metrics used here are: Accuracy, Recall, Precision, ROC/AUC and F1.\n",
    "  # these are the industry standard and provide a proper, unbiased benchmark for models.\n",
    "  accuracy_score = metrics.accuracy_score(y_test, predicted)\n",
    "  recall_score = metrics.recall_score(y_test, predicted)\n",
    "  precision_score = metrics.precision_score(y_test, predicted)\n",
    "  roc_auc_score = metrics.roc_auc_score(y_test, predicted)\n",
    "  f1_score = metrics.f1_score(y_test, predicted)\n",
    "\n",
    "  if(verbose):\n",
    "    print(\"Metrics for model name: \" + model_name)\n",
    "    print(\"Accuracy score: \" + accuracy_score.astype(str))\n",
    "    print(\"Recall score: \" + recall_score.astype(str))\n",
    "    print(\"Precision_score: \" + precision_score.astype(str))\n",
    "    print(\"ROC/AUC score: \" + roc_auc_score.astype(str))\n",
    "    print(\"F1 score: \" + f1_score.astype(str))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "  # return data for sorting later\n",
    "  return [model_name,accuracy_score,recall_score,precision_score,roc_auc_score,f1_score]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292831,
     "status": "ok",
     "timestamp": 1610128636730,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "X8RXyMv87sj0",
    "outputId": "7a526f41-bb1c-4de2-c77b-849e4cf20e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here we have our \"baseline\" SVM, as defined by sklearn. \n",
    "# let's get its preformance to compare it to our other parameters:\n",
    "\n",
    "baseline_SVM = svm.SVC()\n",
    "baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(baseline_SVM,\"Baseline SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE-E6_o__Tge"
   },
   "source": [
    "#Comparing the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129509,
     "status": "ok",
     "timestamp": 1610135785500,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "089SRiiH8uBq",
    "outputId": "955c85ac-afa3-496c-aac2-3505950132d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Linear SVM\n",
      "Accuracy score: 0.8216666666666667\n",
      "Recall score: 0.23380726698262244\n",
      "Precision_score: 0.7474747474747475\n",
      "ROC/AUC score: 0.6063417408001409\n",
      "F1 score: 0.3561973525872443\n",
      "\n",
      "\n",
      "Metrics for model name: Polynomial SVM\n",
      "Accuracy score: 0.8176666666666667\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7057416267942583\n",
      "ROC/AUC score: 0.6035175607734309\n",
      "F1 score: 0.3503562945368171\n",
      "\n",
      "\n",
      "Metrics for model name: Sigmoid SVM\n",
      "Accuracy score: 0.695\n",
      "Recall score: 0.3175355450236967\n",
      "Precision_score: 0.29385964912280704\n",
      "ROC/AUC score: 0.5567398891151437\n",
      "F1 score: 0.30523917995444194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our baseline SVM has a radial basis function(rbf) kernel, so lets test the other kernel used in the algorithm\n",
    "\n",
    "# SVM with a linear kernel \n",
    "poly_SVM = svm.SVC(kernel=\"linear\")\n",
    "poly_SVM.fit(X_train, y_train)\n",
    "evalModel(poly_SVM,\"Linear SVM\", True)\n",
    "\n",
    "\n",
    "# SVM with a polynomial kernel (default degree = 3 )\n",
    "poly_SVM = svm.SVC(kernel=\"poly\")\n",
    "poly_SVM.fit(X_train, y_train)\n",
    "evalModel(poly_SVM,\"Polynomial SVM\", True)\n",
    "\n",
    "\n",
    "# SVM with a sigmoid kernel \n",
    "sig_SVM = svm.SVC(kernel=\"sigmoid\")\n",
    "sig_SVM.fit(X_train, y_train)\n",
    "evalModel(sig_SVM,\"Sigmoid SVM\", True);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsDtRKL8FRlb"
   },
   "source": [
    "Observation: \n",
    "\n",
    "The polynomial kernel SVM seems to prefrom better than the baseline radial basis function one. \n",
    "\n",
    "Whereas the Sigmoid SVM seems to preform worst in every metric compared to the 2 others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vYkKP6mcari"
   },
   "source": [
    "#Degrees for polynomial kernel\n",
    "The polynomial kernel seemed to preform well, so let's see if we can increase further the preformance of the model by fine tuning the degree of the polynomial kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654756,
     "status": "ok",
     "timestamp": 1610136440264,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "DP9X8VnWB0Ez",
    "outputId": "61438620-b171-4642-dcaf-d0a352aa4232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted order of polynomial SVMs by accuracy\n",
      "Polynomial SVM with degree:3\n",
      "Accuracy score: 0.8176666666666667\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7057416267942583\n",
      "ROC/AUC score: 0.6035175607734309\n",
      "F1 score: 0.3503562945368171\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:4\n",
      "Accuracy score: 0.8105\n",
      "Recall score: 0.2037914691943128\n",
      "Precision_score: 0.6666666666666666\n",
      "ROC/AUC score: 0.5882708930255467\n",
      "F1 score: 0.31215970961887474\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:5\n",
      "Accuracy score: 0.8055\n",
      "Recall score: 0.1895734597156398\n",
      "Precision_score: 0.6299212598425197\n",
      "ROC/AUC score: 0.5798944611632698\n",
      "F1 score: 0.2914389799635701\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:6\n",
      "Accuracy score: 0.7996666666666666\n",
      "Recall score: 0.16429699842022116\n",
      "Precision_score: 0.5909090909090909\n",
      "ROC/AUC score: 0.5669393737348254\n",
      "F1 score: 0.25710754017305315\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:2\n",
      "Accuracy score: 0.7955\n",
      "Recall score: 0.04265402843601896\n",
      "Precision_score: 0.782608695652174\n",
      "ROC/AUC score: 0.5197427303143339\n",
      "F1 score: 0.08089887640449439\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our original testing with a polynomial kernel had degree 3\n",
    "# choosing and testing this is crucial. as too small a kernel will lead to underfitting and too big a kernel will lead to overfitting\n",
    "\n",
    "# here, we will test different degrees of  polynomial kerenels, from 2 to 4. \n",
    "# this range has been selected as 2 is the minimum for a polynomial funciton, and with a degree above 4, not only do training times get too long, but we risk overfitting\n",
    "# too long to train above 4\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_polynomial_kernel = []\n",
    "\n",
    "# loop to test our polynomial kernel with different degrees\n",
    "for k in range(2, 7): \n",
    "\n",
    "  poly_SVM = svm.SVC(kernel=\"poly\", degree = k)\n",
    "  poly_SVM.fit(X_train, y_train)\n",
    "  history_result_polynomial_kernel.append(evalModel(poly_SVM,\"Polynomial SVM with degree:\" + str(k)))\n",
    "\n",
    "\n",
    "# helper function to sort our results by accuracy \n",
    "def Sort(array): \n",
    "    # sorts a 2D array using the 2nd element (our accuracy) in descending order\n",
    "    array.sort(key = lambda x: x[1],  reverse=True) \n",
    "    return array \n",
    "\n",
    "# sort our results\n",
    "sorted_results = Sort(history_result_polynomial_kernel)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of polynomial SVMs by accuracy\")\n",
    "for result in sorted_results:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Ec9ctfdkl8"
   },
   "source": [
    "Observation: \n",
    "\n",
    "The base degree of 3 seems to preform the best, and the sorted results follow our hypothesis in the code comments. \n",
    "\n",
    "<!-- \n",
    "Increasing the degree of the polynomial kernel seems to ameliorate the metrics of this type of model\n",
    "\n",
    "However, we know that increasing the degree of the polynomial kernel makes our model more prone to overfitting, and thus should be considered if we were to move forwards with this model.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8yf-RwxcBuQ"
   },
   "source": [
    "#Gamma kernel coefficent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41486,
     "status": "ok",
     "timestamp": 1610135240545,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "c2cUAoCvCQH3",
    "outputId": "313501f0-20ff-48a8-96f9-6a461ee8394b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: poly SVM  with auto gamma \n",
      "Accuracy score: 0.8176666666666667\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7057416267942583\n",
      "ROC/AUC score: 0.6035175607734309\n",
      "F1 score: 0.3503562945368171\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['poly SVM  with auto gamma ',\n",
       " 0.8176666666666667,\n",
       " 0.2330173775671406,\n",
       " 0.7057416267942583,\n",
       " 0.6035175607734309,\n",
       " 0.3503562945368171]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default kernel coefficent(gamma) for our SVM is \"scale\"(1 / (n_features * X.var())\n",
    "# here, we are testing \"auto\", which uses 1 / n_features\n",
    "\n",
    "# the kernel coeffiagamma kernel coefficeint for rbf, poly and sigmoid\n",
    "# first testing has gamma  =  scale, here we test for auto\n",
    "\n",
    "\n",
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\")\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma\", True);\n",
    "\n",
    "# polynomial kernel SVM \n",
    "auto_poly_SVM = svm.SVC(kernel=\"poly\",gamma = \"auto\")\n",
    "auto_poly_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_poly_SVM,\"Polynomial SVM with auto gamma\", True)\n",
    "\n",
    "# sigmoid kernel SVM\n",
    "auto_sig_SVM = svm.SVC(kernel=\"sigmoid\", gamma = \"auto\")\n",
    "auto_sig_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_sig_SVM,\"Sigmoid SVM with auto gamma\", True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnYvmb19DPo7"
   },
   "source": [
    "Obersvation:\n",
    "\n",
    "<!-- The results with the radial basis function are incredible in every metric. \n",
    "\n",
    "We could further hypothesise that this method would work even better with a polynomial kernel of degree 4, however the training times are too long to consider this. \n",
    "\n",
    "On the other hand, this method seems to preform very poorly with a sigmoid kernel. -->\n",
    "\n",
    "The gamma kernel coefficent dosen't change the preformance of models significantly, and thus we won't use it in our final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lLpNvM65S4G"
   },
   "source": [
    "#Shrinking  parameter\n",
    "This parameter is used to shorten the training time by solve the optimization problem a bit more loosely. \n",
    "\n",
    "We are testing it to see if it impacts the preformance of our models significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 754880,
     "status": "ok",
     "timestamp": 1610129098797,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "iHBfm0DvGA8Z",
    "outputId": "38e2f13d-ec9d-426e-dbf4-a19146a814de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "Metrics for model name: poly SVM\n",
      "Accuracy score: 0.8175\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7040572792362768\n",
      "ROC/AUC score: 0.6034119418465193\n",
      "F1 score: 0.3501483679525223\n",
      "\n",
      "\n",
      "Metrics for model name: sigmoid SVM\n",
      "Accuracy score: 0.695\n",
      "Recall score: 0.3175355450236967\n",
      "Precision_score: 0.29385964912280704\n",
      "ROC/AUC score: 0.5567398891151437\n",
      "F1 score: 0.30523917995444194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test shrinking parameter, default = true\n",
    "\n",
    "# baseline rbf kernel SVM\n",
    "non_shrink_baseline_SVM = svm.SVC(shrinking = False)\n",
    "non_shrink_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_baseline_SVM,\"Baseline SVM\", True);\n",
    "\n",
    "# polynomial kernel SVM\n",
    "non_shrink_poly_SVM = svm.SVC(kernel=\"poly\",shrinking = False)\n",
    "non_shrink_poly_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_poly_SVM,\"poly SVM\", True)\n",
    "\n",
    "# sigmoid kernel SVM\n",
    "non_shrink_sig_SVM = svm.SVC(kernel=\"sigmoid\",shrinking = False)\n",
    "non_shrink_sig_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_sig_SVM,\"sigmoid SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP-jOE0l99T0"
   },
   "source": [
    "Observation:\n",
    "\n",
    "The shrinking  parameter dosen't change the preformance of models significantly. \n",
    "\n",
    "As this parameter has an impact preformance, we will therefore keep it as default(True) for our final model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGhmwj1s-UJC"
   },
   "source": [
    "#Regularization parameter\n",
    "The regularization parameter is very important to avoid overfitting the model to our dataset.  The strength of the regularization is inversely proportional to C, and must be strictly positive. The penalty is a squared l2 penalty.\n",
    "\n",
    "We will test different values for this parameter and see its impact on the model preformance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1148971,
     "status": "ok",
     "timestamp": 1610129492892,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "Tw5QZybJMORx",
    "outputId": "b91f27c9-9e9b-4927-a978-8fd2f45a08f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted order of baseline SVMs by accuracy\n",
      "baseline SVM with regularization parameter C = 4\n",
      "Accuracy score: 0.8315\n",
      "Recall score: 0.33649289099526064\n",
      "Precision_score: 0.7135678391959799\n",
      "ROC/AUC score: 0.6501856089957292\n",
      "F1 score: 0.4573268921095008\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 3\n",
      "Accuracy score: 0.8308333333333333\n",
      "Recall score: 0.334913112164297\n",
      "Precision_score: 0.7102177554438861\n",
      "ROC/AUC score: 0.649184481726424\n",
      "F1 score: 0.4551798174986581\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 5\n",
      "Accuracy score: 0.8306666666666667\n",
      "Recall score: 0.3341232227488152\n",
      "Precision_score: 0.709731543624161\n",
      "ROC/AUC score: 0.648789537018683\n",
      "F1 score: 0.4543501611170784\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 1\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 2\n",
      "Accuracy score: 0.83\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.7063758389261745\n",
      "ROC/AUC score: 0.6477884097493778\n",
      "F1 score: 0.45220193340494097\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 6\n",
      "Accuracy score: 0.8296666666666667\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.7040133779264214\n",
      "ROC/AUC score: 0.6475771718955545\n",
      "F1 score: 0.4517167381974249\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 7\n",
      "Accuracy score: 0.8288333333333333\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.6981757877280266\n",
      "ROC/AUC score: 0.6470490772609958\n",
      "F1 score: 0.45050829320492247\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all our previous models had as default the regularization parameter C =1. \n",
    "# as our C must be stricly positive, we'll test our baseline model with different values (from 2 to 8), and we should expect the accruacy to stop increasing after a point.\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_reg_param = []\n",
    "\n",
    "# loop to test our baseline with \n",
    "for n in range(1, 8): \n",
    "\n",
    "  SVM = svm.SVC(C = n)\n",
    "  SVM.fit(X_train, y_train)\n",
    "  history_result_reg_param.append(evalModel(SVM,\"baseline SVM with regularization parameter C = \" + str(n)))\n",
    "\n",
    "\n",
    "# sort our results\n",
    "sorted_results_reg = Sort(history_result_reg_param)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of baseline SVMs by accuracy\")\n",
    "for result in sorted_results_reg:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmZeApjF-Tab"
   },
   "source": [
    "Observation: \n",
    "\n",
    "As expected with a stronger regularization parameter, the metrics for the model are improved with a stronger regularization term, but only to a point where increasing it further  decreases the quality of the model, thus telling us that it has become overbearing. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHvJqrf0JHGU"
   },
   "source": [
    "#Conclusion\n",
    "\n",
    "Let's take our parameters and evaluate them in the context of the broader SVM model:\n",
    "\n",
    "*  The type of kernel: \n",
    "  * Best preformance by baseline\n",
    "  * linear kernel close second\n",
    "  * Decent by polynomial\n",
    "  * Below average for sigmoid \n",
    "\n",
    "*  The degree for polynomial kernels:\n",
    " * Best preformance by default of 3, higher and we are overfitting, lower and we are underfitting\n",
    " * However, preformance metrics for polynomial kernels are still all lower than linear and rbf kernels\n",
    "\n",
    "\n",
    "*  The gamma kernel coefficent\n",
    " * No effect on the preformance of SVM models\n",
    "\n",
    "* The shrinking heuristic\n",
    " * No effect on the preformance of SVM models\n",
    "\n",
    "* The strength of the regularization \n",
    " * Increasing regularization increases the model preformance\n",
    "  * Too much regularization decreases the model preformance\n",
    "\n",
    "\n",
    "Using the \"Darwinism\" approach we should theoretically be able to create the best model using the baseline (rbf) SVM with C=4 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1249764,
     "status": "ok",
     "timestamp": 1610129593690,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "fWTJ7MgKLIW_",
    "outputId": "32bd083b-9dfd-4848-ab37-32a5c0760050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM with auto gamma\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "Metrics for model name: Baseline SVM with auto gamma and reg param 4\n",
      "Accuracy score: 0.8315\n",
      "Recall score: 0.33649289099526064\n",
      "Precision_score: 0.7135678391959799\n",
      "ROC/AUC score: 0.6501856089957292\n",
      "F1 score: 0.4573268921095008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best SVM model\n",
    "auto_baseline_SVM = svm.SVC(C=4)\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Best model: our baseline SVM (radial basis function) kernel with a regularization parameter of C = 4\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olDz1Of0h7Rx"
   },
   "source": [
    "We can observe that the metrics for this final model are better then itself without the added parameter, and all the other models. Thus testing the parameters individually and combining them has proved to be fruitful."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPEpqq+WI5tDZl314Rw9N1A",
   "collapsed_sections": [],
   "name": "SVM model seleciton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
