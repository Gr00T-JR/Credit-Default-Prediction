{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfYMF36uRqdT"
   },
   "source": [
    "#Motivation:\n",
    "\n",
    "In the larger scope of ML algorithms, we've now determinted that the most appropriate model for our situation is the SVM. \n",
    "\n",
    "However, these models have many intricacies  that vastly change their preformance and usabilty, thus, we will further our model selection to pick the most appropriate parameters for our model.\n",
    "\n",
    "For this, we will take a \"Darwinist\" approach. By testing all these parameteres seperatly against a \"baseline\" SVM model (as defined by sklearn), and picking the best preforming one, we should be able to hypothetically create the \"best\" model for out dataset. However, there are some rammifications of not testing certain parameters together, which we will detail and talk about.\n",
    "\n",
    "The SVM parameters we are evaulation are as such:\n",
    "\n",
    "*  The type of kernel\n",
    "*  The degree for polynomial kernels\n",
    "*  The gamma kernel coefficent\n",
    "* The shrinking heuristic\n",
    "* The strength of the regularization parameter\n",
    "\n",
    "\n",
    "However, it is also worth nothing that we won't experiment with some parameters. For example, we will be using the same tolerance for stoping criterion (1e-3) as we want to keep the bound on the relative error of our models comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 250886,
     "status": "ok",
     "timestamp": 1610128594782,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "SRy8j8kp0VCr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function used to evaluate different SVM models\n",
    "def evalModel(model, model_name, verbose = False):\n",
    "  # every model is evaluated against the same test dataset\n",
    "\n",
    "  # use the model passed as a parameter to make predictions, which we will use to judge the model \n",
    "  predicted = model.predict(X_test)\n",
    "\n",
    "  # metrics used here are: Accuracy, Recall, Precision, ROC/AUC and F1.\n",
    "  # these are the industry standard and provide a proper, unbiased benchmark for models.\n",
    "  accuracy_score = metrics.accuracy_score(y_test, predicted)\n",
    "  recall_score = metrics.recall_score(y_test, predicted)\n",
    "  precision_score = metrics.precision_score(y_test, predicted)\n",
    "  roc_auc_score = metrics.roc_auc_score(y_test, predicted)\n",
    "  f1_score = metrics.f1_score(y_test, predicted)\n",
    "\n",
    "  if(verbose):\n",
    "    print(\"Metrics for model name: \" + model_name)\n",
    "    print(\"Accuracy score: \" + accuracy_score.astype(str))\n",
    "    print(\"Recall score: \" + recall_score.astype(str))\n",
    "    print(\"Precision_score: \" + precision_score.astype(str))\n",
    "    print(\"ROC/AUC score: \" + roc_auc_score.astype(str))\n",
    "    print(\"F1 score: \" + f1_score.astype(str))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "  # return data for sorting later\n",
    "  return [model_name,accuracy_score,recall_score,precision_score,roc_auc_score,f1_score]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292831,
     "status": "ok",
     "timestamp": 1610128636730,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "X8RXyMv87sj0",
    "outputId": "7a526f41-bb1c-4de2-c77b-849e4cf20e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here we have our \"baseline\" SVM, as defined by sklearn. \n",
    "# let's get its preformance to compare it to our other parameters:\n",
    "\n",
    "baseline_SVM = svm.SVC()\n",
    "baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(baseline_SVM,\"Baseline SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE-E6_o__Tge"
   },
   "source": [
    "#Comparing the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361986,
     "status": "ok",
     "timestamp": 1610128705890,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "089SRiiH8uBq",
    "outputId": "f37aed79-dbec-425e-946d-7078d2a3fd33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Polynomial SVM\n",
      "Accuracy score: 0.8176666666666667\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7057416267942583\n",
      "ROC/AUC score: 0.6035175607734309\n",
      "F1 score: 0.3503562945368171\n",
      "\n",
      "\n",
      "Metrics for model name: Sigmoid SVM\n",
      "Accuracy score: 0.695\n",
      "Recall score: 0.3175355450236967\n",
      "Precision_score: 0.29385964912280704\n",
      "ROC/AUC score: 0.5567398891151437\n",
      "F1 score: 0.30523917995444194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our baseline SVM has a radial basis function kernel, so lets test the other kernel used in the algorithm\n",
    "\n",
    "# our data isn't linearly separable, so using a linear kernel isn't feasable and therefore not worth testing \n",
    "\n",
    "# SVM with a polynomial kernel (default degree = 3 )\n",
    "poly_SVM = svm.SVC(kernel=\"poly\")\n",
    "poly_SVM.fit(X_train, y_train)\n",
    "evalModel(poly_SVM,\"Polynomial SVM\", True)\n",
    "\n",
    "\n",
    "# SVM with a sigmoid kernel \n",
    "sig_SVM = svm.SVC(kernel=\"sigmoid\")\n",
    "sig_SVM.fit(X_train, y_train)\n",
    "evalModel(sig_SVM,\"Sigmoid SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsDtRKL8FRlb"
   },
   "source": [
    "Observation: \n",
    "\n",
    "The polynomial kernel SVM seems to prefrom better than the baseline radial basis function one. \n",
    "\n",
    "Whereas the Sigmoid SVM seems to preform worst in every metric compared to the 2 others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vYkKP6mcari"
   },
   "source": [
    "#Degrees for polynomial kernel\n",
    "The polynomial kernel seemed to preform well, so let's see if we can increase further the preformance of the model by fine tuning the degree of the polynomial kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510662,
     "status": "ok",
     "timestamp": 1610128854572,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "DP9X8VnWB0Ez",
    "outputId": "e179d5fa-7fe3-49b0-9566-4a93529219d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted order of polynomial SVMs by accuracy\n",
      "Polynomial SVM with degree:3\n",
      "Accuracy score: 0.8176666666666667\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7057416267942583\n",
      "ROC/AUC score: 0.6035175607734309\n",
      "F1 score: 0.3503562945368171\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:4\n",
      "Accuracy score: 0.8105\n",
      "Recall score: 0.2037914691943128\n",
      "Precision_score: 0.6666666666666666\n",
      "ROC/AUC score: 0.5882708930255467\n",
      "F1 score: 0.31215970961887474\n",
      "\n",
      "\n",
      "Polynomial SVM with degree:2\n",
      "Accuracy score: 0.7955\n",
      "Recall score: 0.04265402843601896\n",
      "Precision_score: 0.782608695652174\n",
      "ROC/AUC score: 0.5197427303143339\n",
      "F1 score: 0.08089887640449439\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our original testing with a polynomial kernel had degree 3\n",
    "# choosing and testing this is crucial. as too small a kernel will lead to underfitting and too big a kernel will lead to overfitting\n",
    "\n",
    "# here, we will test different degrees of  polynomial kerenels, from 2 to 4. \n",
    "# this range has been selected as 2 is the minimum for a polynomial funciton, and with a degree above 4, not only do training times get too long, but we risk overfitting\n",
    "# too long to train above 4\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_polynomial_kernel = []\n",
    "\n",
    "# loop to test our polynomial kernel with different degrees\n",
    "for k in range(2, 5): \n",
    "\n",
    "  poly_SVM = svm.SVC(kernel=\"poly\", degree = k)\n",
    "  poly_SVM.fit(X_train, y_train)\n",
    "  history_result_polynomial_kernel.append(evalModel(poly_SVM,\"Polynomial SVM with degree:\" + str(k)))\n",
    "\n",
    "\n",
    "# helper function to sort our results by accuracy \n",
    "def Sort(array): \n",
    "    # sorts a 2D array using the 2nd element (our accuracy) in descending order\n",
    "    array.sort(key = lambda x: x[1],  reverse=True) \n",
    "    return array \n",
    "\n",
    "# sort our results\n",
    "sorted_results = Sort(history_result_polynomial_kernel)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of polynomial SVMs by accuracy\")\n",
    "for result in sorted_results:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Ec9ctfdkl8"
   },
   "source": [
    "Observation: \n",
    "\n",
    "Increasing the degree of the polynomial kernel seems to ameliorate the metrics of this type of model\n",
    "\n",
    "However, we know that increasing the degree of the polynomial kernel makes our model more prone to overfitting, and thus should be considered if we were to move forwards with this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 582950,
     "status": "ok",
     "timestamp": 1610128926864,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "c2cUAoCvCQH3",
    "outputId": "36f0121c-bde7-41af-9340-7dcc750cae2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM with auto gamma\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "Metrics for model name: sigmoid SVM with auto gamma\n",
      "Accuracy score: 0.695\n",
      "Recall score: 0.3175355450236967\n",
      "Precision_score: 0.29385964912280704\n",
      "ROC/AUC score: 0.5567398891151437\n",
      "F1 score: 0.30523917995444194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the default kernel coefficent(gamma) for our SVM is \"scale\"(1 / (n_features * X.var())\n",
    "# here, we are testing \"auto\", which uses 1 / n_features\n",
    "\n",
    "# the kernel coeffiagamma kernel coefficeint for rbf, poly and sigmoid\n",
    "# first testing has gamma  =  scale, here we test for auto\n",
    "\n",
    "\n",
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\")\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma\", True);\n",
    "\n",
    "# \"auto\" gamma and a polynomial kernel is nearly impossible to train \n",
    "# auto_poly_SVM = svm.SVC(kernel=\"poly\",gamma = \"auto\")\n",
    "# auto_poly_SVM.fit(X_train, y_train)\n",
    "# evalModel(auto_poly_SVM,\"poly SVM  with auto gamma \", True)\n",
    "\n",
    "# sigmoid kernel SVM\n",
    "auto_sig_SVM = svm.SVC(kernel=\"sigmoid\", gamma = \"auto\")\n",
    "auto_sig_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_sig_SVM,\"sigmoid SVM with auto gamma\", True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnYvmb19DPo7"
   },
   "source": [
    "Obersvation:\n",
    "\n",
    "The results with the radial basis function are incredible in every metric. \n",
    "\n",
    "We could further hypothesise that this method would work even better with a polynomial kernel of degree 4, however the training times are too long to consider this. \n",
    "\n",
    "On the other hand, this method seems to preform very poorly with a sigmoid kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lLpNvM65S4G"
   },
   "source": [
    "#Shrinking  parameter\n",
    "This parameter is used to shorten the training time by solve the optimization problem a bit more loosely. \n",
    "\n",
    "We are testing it to see if it impacts the preformance of our models significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 754880,
     "status": "ok",
     "timestamp": 1610129098797,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "iHBfm0DvGA8Z",
    "outputId": "38e2f13d-ec9d-426e-dbf4-a19146a814de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "Metrics for model name: poly SVM\n",
      "Accuracy score: 0.8175\n",
      "Recall score: 0.2330173775671406\n",
      "Precision_score: 0.7040572792362768\n",
      "ROC/AUC score: 0.6034119418465193\n",
      "F1 score: 0.3501483679525223\n",
      "\n",
      "\n",
      "Metrics for model name: sigmoid SVM\n",
      "Accuracy score: 0.695\n",
      "Recall score: 0.3175355450236967\n",
      "Precision_score: 0.29385964912280704\n",
      "ROC/AUC score: 0.5567398891151437\n",
      "F1 score: 0.30523917995444194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test shrinking parameter, default = true\n",
    "\n",
    "# baseline rbf kernel SVM\n",
    "non_shrink_baseline_SVM = svm.SVC(shrinking = False)\n",
    "non_shrink_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_baseline_SVM,\"Baseline SVM\", True);\n",
    "\n",
    "# polynomial kernel SVM\n",
    "non_shrink_poly_SVM = svm.SVC(kernel=\"poly\",shrinking = False)\n",
    "non_shrink_poly_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_poly_SVM,\"poly SVM\", True)\n",
    "\n",
    "# sigmoid kernel SVM\n",
    "non_shrink_sig_SVM = svm.SVC(kernel=\"sigmoid\",shrinking = False)\n",
    "non_shrink_sig_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_sig_SVM,\"sigmoid SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP-jOE0l99T0"
   },
   "source": [
    "Observation:\n",
    "\n",
    "The shrinking  parameter dosen't change the preformance of models significantly. \n",
    "\n",
    "As this parameter has an impact preformance, we will therefore keep it as default(True) for our final model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGhmwj1s-UJC"
   },
   "source": [
    "#Regularization parameter\n",
    "The regularization parameter is very important to avoid overfitting the model to our dataset.  The strength of the regularization is inversely proportional to C, and must be strictly positive. The penalty is a squared l2 penalty.\n",
    "\n",
    "We will test different values for this parameter and see its impact on the model preformance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Tw5QZybJMORx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted order of baseline SVMs by accuracy\n",
      "baseline SVM with regularization parameter C = 4\n",
      "Accuracy score: 0.8315\n",
      "Recall score: 0.33649289099526064\n",
      "Precision_score: 0.7135678391959799\n",
      "ROC/AUC score: 0.6501856089957292\n",
      "F1 score: 0.4573268921095008\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 3\n",
      "Accuracy score: 0.8308333333333333\n",
      "Recall score: 0.334913112164297\n",
      "Precision_score: 0.7102177554438861\n",
      "ROC/AUC score: 0.649184481726424\n",
      "F1 score: 0.4551798174986581\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 5\n",
      "Accuracy score: 0.8306666666666667\n",
      "Recall score: 0.3341232227488152\n",
      "Precision_score: 0.709731543624161\n",
      "ROC/AUC score: 0.648789537018683\n",
      "F1 score: 0.4543501611170784\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 1\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 2\n",
      "Accuracy score: 0.83\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.7063758389261745\n",
      "ROC/AUC score: 0.6477884097493778\n",
      "F1 score: 0.45220193340494097\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 6\n",
      "Accuracy score: 0.8296666666666667\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.7040133779264214\n",
      "ROC/AUC score: 0.6475771718955545\n",
      "F1 score: 0.4517167381974249\n",
      "\n",
      "\n",
      "baseline SVM with regularization parameter C = 7\n",
      "Accuracy score: 0.8288333333333333\n",
      "Recall score: 0.3325434439178515\n",
      "Precision_score: 0.6981757877280266\n",
      "ROC/AUC score: 0.6470490772609958\n",
      "F1 score: 0.45050829320492247\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all our previous models had as default the regularization parameter C =1. \n",
    "# as our C must be stricly positive, we'll test our baseline model with different values (from 2 to 8), and we should expect the accruacy to stop increasing after a point.\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_reg_param = []\n",
    "\n",
    "# loop to test our baseline with \n",
    "for n in range(1, 8): \n",
    "\n",
    "  SVM = svm.SVC(C = n)\n",
    "  SVM.fit(X_train, y_train)\n",
    "  history_result_reg_param.append(evalModel(SVM,\"baseline SVM with regularization parameter C = \" + str(n)))\n",
    "\n",
    "\n",
    "# sort our results\n",
    "sorted_results_reg = Sort(history_result_reg_param)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of baseline SVMs by accuracy\")\n",
    "for result in sorted_results_reg:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmZeApjF-Tab"
   },
   "source": [
    "Observation: \n",
    "\n",
    "As expected with a stronger regularization parameter, the metrics for the model are improved with a stronger regularization term, but only to a point where increasing it further  decreases the quality of the model, thus telling us that it has become overbearing. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHvJqrf0JHGU"
   },
   "source": [
    "#Conclusion\n",
    "\n",
    "Let's take our parameters and evaluate them in the context of the broader SVM model:\n",
    "\n",
    "*  The type of kernel: \n",
    "  * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "*  The degree for polynomial kernels:\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "*  The gamma kernel coefficent\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "  \n",
    "* The shrinking heuristic\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "* The strength of the regularization \n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fWTJ7MgKLIW_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model name: Baseline SVM with auto gamma\n",
      "Accuracy score: 0.8301666666666667\n",
      "Recall score: 0.3333333333333333\n",
      "Precision_score: 0.7068676716917923\n",
      "ROC/AUC score: 0.6481833544571186\n",
      "F1 score: 0.45303274288781537\n",
      "\n",
      "\n",
      "Metrics for model name: Baseline SVM with auto gamma and reg param 4\n",
      "Accuracy score: 0.8315\n",
      "Recall score: 0.33649289099526064\n",
      "Precision_score: 0.7135678391959799\n",
      "ROC/AUC score: 0.6501856089957292\n",
      "F1 score: 0.4573268921095008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\")\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma\", True);\n",
    "\n",
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\", C=4)\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma and reg param 4\", True);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPxXTT5EmL4OSJHOXYqMpkS",
   "collapsed_sections": [],
   "name": "SVM model seleciton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
