{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Draft 1\n",
    "\n",
    "1. Data Cleaning / EDA\n",
    "2. Oversampling (SMOTE + ENN)\n",
    "3. Feature Engineering/Creation\n",
    "    1. Timeseries Clustering\n",
    "        1. `PAY`, `PAY_AMT`\n",
    "    2. Encoding Domain Expertise\n",
    "        1. X\n",
    "        2. X\n",
    "        3. X\n",
    "4. Outlier Removal\n",
    "5. Feature Selection\n",
    "    1. Weight-based\n",
    "    2. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "* **Imports**\n",
    "* **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.822020Z",
     "start_time": "2021-01-06T21:00:36.808982Z"
    }
   },
   "outputs": [],
   "source": [
    "# general tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#sns.set_style(\"dark\")\n",
    "#sns.set_context(\"paper\")\n",
    "\n",
    "# preprocessing\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import get_variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.919381Z",
     "start_time": "2021-01-06T21:00:38.823951Z"
    }
   },
   "outputs": [],
   "source": [
    "# data imports\n",
    "\n",
    "### EDIT FILEPATH IF NECESSARY\n",
    "root = '.'\n",
    "data_dir = '/DataFiles/'\n",
    "\n",
    "# form filepaths\n",
    "data_path = root + data_dir\n",
    "train_file = data_path + 'CreditCard_train.csv'\n",
    "test_file = data_path + 'CreditCard_test.csv'\n",
    "\n",
    "# load\n",
    "_df_train = pd.read_csv(train_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "_df_test = pd.read_csv(test_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & EDA\n",
    "\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "To be cleaned:\n",
    "* `AGE`: Creation of 'bins'\n",
    "* `EDUCATION`: Grouping categories `4,5,6,0`\n",
    "* `PAY_n`: Categorical/One-Hot Encoding\n",
    "* `SEX`: Categorical/One-Hot Encoding\n",
    "* `MARRIAGE`: Grouping categories `0` and `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.930180Z",
     "start_time": "2021-01-06T21:00:38.923794Z"
    }
   },
   "outputs": [],
   "source": [
    "# create copy df for handling\n",
    "df_train = _df_train.copy()\n",
    "df_test = _df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset can be changed for whatever after feature selection\n",
    "\n",
    "# split X, y\n",
    "X_train, y_train = df_train.iloc[:,:-1], df_train.iloc[:,-1:] #not necessary yet\n",
    "X_test, y_test = df_test.iloc[:,:-1], df_test.iloc[:,-1:]\n",
    "\n",
    "# reshape y into 1d column vector\n",
    "y_train, y_test = np.reshape(y_train, (y_train.shape[0],)), np.reshape(y_test, (y_test.shape[0],))\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "# y_train = preprocessing.scale(y_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "# y_test = preprocessing.scale(y_test)\n",
    "\n",
    "\n",
    "# # unravel labels for SVM\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining Datasets\n",
    "\n",
    "The Feature Engineering section has cleaned, augmented, and reduced the original dataset into **three sets of features**, each for a corresponding Feature Selection method. Each method and their corresponding DataFrame (excl. target var.) is listed below:\n",
    "\n",
    "1. Weighted Approach: `df_weighted_features`\n",
    "2. Heuristic Approach: `df_nbr_features`\n",
    "3. PCA Approach: `df_pca_25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat eng pipeline\n",
    "def feat_eng_pipeline(df):\n",
    "    '''\n",
    "    Returns engineered dataset.\n",
    "    '''\n",
    "    # create bins for 'AGE'\n",
    "    df['AGE_BIN'] = pd.cut(df['AGE'],\n",
    "                              bins=[20,40,60,100],\n",
    "                              labels=[1,2,3])\n",
    "    # drop 'AGE'\n",
    "    df.drop(['AGE'], axis=1, inplace=True)\n",
    "    # Group 4,5,6,0 categories for 'EDUCATION'\n",
    "    ed_map = {1:1, 2:2, 3:3, 4:4, 5:4, 6:4, 0:4}\n",
    "    df.EDUCATION = df.EDUCATION.map(ed_map)\n",
    "    # Group 0, 3 categories for 'MARRIAGE'\n",
    "    marr_map = {0:0, 1:1, 2:2, 3:0}\n",
    "    df.MARRIAGE = df.MARRIAGE.map(marr_map)\n",
    "    # encoding categoricals\n",
    "    categoricals = ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE_BIN']\n",
    "    for col in categoricals: \n",
    "        df[col] = df[col].astype('category')\n",
    "    # create dummy cols, join, and drop old\n",
    "    cat_df = df[categoricals]\n",
    "    cat_df = pd.get_dummies(cat_df)\n",
    "    df = df.join(cat_df).drop(categoricals, axis=1)\n",
    "    \n",
    "    # define features\n",
    "    pay_features = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "    pay_amt_features = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "    \n",
    "    # create PAY clusters\n",
    "    df_pay = df[pay_features]\n",
    "    pay_clusters = _kmeans_pay[3].predict(df_pay)\n",
    "    df_pay_clusters = pd.DataFrame({'PAY_CLUSTER':pay_clusters})\n",
    "    df_pay_clusters['PAY_CLUSTER'] = df_pay_clusters['PAY_CLUSTER'].astype('category')\n",
    "    \n",
    "    # one-hot encode\n",
    "    cat_df_pc = pd.get_dummies(df_pay_clusters)\n",
    "    cat_df_pc.index = df.index\n",
    "    df = df.join(cat_df_pc)\n",
    "    \n",
    "    # create PAY_AMT clusters\n",
    "    df_pay_amt = df[pay_amt_features]\n",
    "    pay_amt_clusters = _kmeans_pay_amt[3].predict(df_pay_amt)\n",
    "    df_pay_amt_clusters = pd.DataFrame({'PAY_AMT_CLUSTER':pay_amt_clusters})\n",
    "    df_pay_amt_clusters['PAY_AMT_CLUSTER'] = df_pay_amt_clusters['PAY_AMT_CLUSTER'].astype('category')\n",
    "    \n",
    "    # one-hot encode\n",
    "    cat_df_pamtc = pd.get_dummies(df_pay_amt_clusters)\n",
    "    cat_df_pamtc.index = df.index\n",
    "    df = df.join(cat_df_pamtc)\n",
    "    \n",
    "    # average repayment status\n",
    "    df['AVG_PAY'] = get_avg(df, pay_features)\n",
    "    \n",
    "    # 'sufficiency'\n",
    "    pay_amt_features = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "    bill_features = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "    df['AVG_BILL_AMT'] = get_avg(df, bill_features)\n",
    "    df['AVG_PAY_AMT'] = get_avg(df, pay_amt_features)\n",
    "    df['SUFF'] = np.where(df['AVG_BILL_AMT'] <= df['AVG_PAY_AMT'], 1, 0)\n",
    "     \n",
    "    # average change in MoM repayment status\n",
    "    dummy_train = df.copy()\n",
    "    dummy_train['DELTA_12'] = dummy_train['PAY_2'] - dummy_train['PAY_1']\n",
    "    dummy_train['DELTA_23'] = dummy_train['PAY_3'] - dummy_train['PAY_2']\n",
    "    dummy_train['DELTA_34'] = dummy_train['PAY_4'] - dummy_train['PAY_3']\n",
    "    dummy_train['DELTA_45'] = dummy_train['PAY_5'] - dummy_train['PAY_4']\n",
    "    dummy_train['DELTA_56'] = dummy_train['PAY_6'] - dummy_train['PAY_5']\n",
    "    deltas = ['DELTA_12', 'DELTA_23', 'DELTA_34', 'DELTA_45', 'DELTA_56']\n",
    "    dummy_train['AVG_DELTA'] = dummy_train[deltas].mean(axis=1)\n",
    "    df['AVG_PAY_DELTA'] = dummy_train['AVG_DELTA']\n",
    "    \n",
    "    # frequency variables\n",
    "    for pay_feature in pay_features:\n",
    "        df['FREQ_{}'.format(pay_feature)] = np.where((df[pay_feature] >= 3),1, \n",
    "                                                    (np.where(df[pay_feature] <3,0, df[pay_feature])))\n",
    "    pay_delays = ['FREQ_PAY_1', 'FREQ_PAY_2','FREQ_PAY_3','FREQ_PAY_4','FREQ_PAY_5','FREQ_PAY_6',]\n",
    "    df['PAY_DELAY_FREQ'] = df[pay_delays].sum(axis=1)\n",
    "    for pay_feature in pay_features:\n",
    "        df['TIMELY_{}'.format(pay_feature)] = np.where((df[pay_feature] <= 0),1, \n",
    "                                                    (np.where(df[pay_feature] >0,0, df[pay_feature])))\n",
    "    pay_timely = ['TIMELY_PAY_1', 'TIMELY_PAY_2','TIMELY_PAY_3','TIMELY_PAY_4','TIMELY_PAY_5','TIMELY_PAY_6',]\n",
    "    df['PAY_TIMELY_FREQ'] = df[pay_timely].sum(axis=1)\n",
    "    df.drop(pay_delays, axis=1, inplace=True)\n",
    "    df.drop(pay_timely, axis=1, inplace=True)\n",
    "    pay_amounts = ['PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n",
    "    for pay_amt_feature in pay_amt_features:\n",
    "        df['FREQ_{}'.format(pay_amt_feature)] = np.where((df[pay_amt_feature] > 0),1, \n",
    "                                                    (np.where(df[pay_amt_feature] <=0,0,\n",
    "                                                     df[pay_amt_feature])))\n",
    "    repayments = ['FREQ_PAY_AMT1', 'FREQ_PAY_AMT2','FREQ_PAY_AMT3','FREQ_PAY_AMT4','FREQ_PAY_AMT5','FREQ_PAY_AMT6',]\n",
    "    df['REPAY_FREQ'] = df[repayments].sum(axis=1)\n",
    "    df.drop(repayments, axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Datasets\n",
    "\n",
    "HA features:['AVG_BILL_AMT',\n",
    " 'AVG_PAY_AMT',\n",
    " 'BILL_AMT1',\n",
    " 'BILL_AMT2',\n",
    " 'BILL_AMT3',\n",
    " 'BILL_AMT4',\n",
    " 'BILL_AMT5',\n",
    " 'BILL_AMT6',\n",
    " 'LIMIT_BAL',\n",
    " 'PAY_AMT1',\n",
    " 'PAY_AMT2',\n",
    " 'PAY_AMT3',\n",
    " 'PAY_AMT4',\n",
    " 'PAY_AMT5',\n",
    " 'PAY_AMT6',\n",
    " 'PAY_AMT_CLUSTER_0',\n",
    " 'PAY_AMT_CLUSTER_1',\n",
    " 'PAY_AMT_CLUSTER_2']\n",
    "\n",
    "PA features:\n",
    "array(['AGE_BIN_1', 'AGE_BIN_2', 'AGE_BIN_3', 'AVG_BILL_AMT', 'AVG_PAY',\n",
    "       'AVG_PAY_AMT', 'AVG_PAY_DELTA', 'BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'EDUCATION_1',\n",
    "       'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4', 'LIMIT_BAL',\n",
    "       'MARRIAGE_0', 'MARRIAGE_1', 'MARRIAGE_2', 'PAY_1', 'PAY_2',\n",
    "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'PAY_AMT1', 'PAY_AMT2',\n",
    "       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "       'PAY_AMT_CLUSTER_0', 'PAY_AMT_CLUSTER_1', 'PAY_AMT_CLUSTER_2',\n",
    "       'PAY_CLUSTER_0', 'PAY_CLUSTER_1', 'PAY_CLUSTER_2', 'PAY_CLUSTER_3',\n",
    "       'PAY_DELAY_FREQ', 'PAY_TIMELY_FREQ', 'REPAY_FREQ', 'SEX_1',\n",
    "       'SEX_2', 'SUFF'], dtype=object)\n",
    "\n",
    "PCA features: the same data from feature engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_kmeans_pay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-f1f8157e85f2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_test_eng\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeat_eng_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_test\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m#preprocessing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdf_train_eng\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfeat_eng_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m## SCALING\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mscaler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mStandardScaler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-5-d1f2c2b3d766>\u001B[0m in \u001B[0;36mfeat_eng_pipeline\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0;31m# create PAY clusters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mdf_pay\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpay_features\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m     \u001B[0mpay_clusters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_kmeans_pay\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_pay\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m     \u001B[0mdf_pay_clusters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'PAY_CLUSTER'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mpay_clusters\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0mdf_pay_clusters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'PAY_CLUSTER'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_pay_clusters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'PAY_CLUSTER'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'category'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name '_kmeans_pay' is not defined"
     ]
    }
   ],
   "source": [
    "df_test_eng = feat_eng_pipeline(df_test) #preprocessing\n",
    "df_train_eng = feat_eng_pipeline(df_train)\n",
    "\n",
    "## SCALING\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling unscaled train data\n",
    "df_weighted_features_scaled = pd.DataFrame(scaler.fit_transform(df_weighted_features.values), \n",
    "                        index=df_weighted_features.index, columns=df_weighted_features.columns)# scaling unscalled train data\n",
    "df_nbr_features_scaled = pd.DataFrame(scaler.fit_transform(df_nbr_features.values), \n",
    "                        index=df_nbr_features.index, columns=df_nbr_features.columns)\n",
    "\n",
    "# scaling test data\n",
    "df_test_eng_scaled = pd.DataFrame(scaler.fit_transform(df_test_eng.values), \n",
    "                        index=df_test_eng.index, columns=df_test_eng.columns)\n",
    "\n",
    "\n",
    "df_test_weighted_features = get_df_features(df_test_eng_scaled.copy(), df_weighted_features.columns.values)\n",
    "df_test_nbr_features = get_df_features(df_test_eng_scaled.copy(), df_nbr_features.columns.values)\n",
    "df_test_pca_features = df_test_eng_scaled.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_WA = df_weighted_features_scaled\n",
    "X_train_HA = df_nbr_features_scaled\n",
    "X_train_PA = df_pca_25\n",
    "\n",
    "X_test_WA = df_test_weighted_features\n",
    "X_test_HA = df_test_nbr_features \n",
    "X_test_PA = pca_25.transform(df_test_eng)\n",
    "\n",
    "dataset_WA = [X_train_WA, X_test_WA]\n",
    "dataset_HA = [X_train_HA, X_test_HA]\n",
    "dataset_PA = [X_train_PA, X_test_PA]\n",
    "\n",
    "datasets = [[dataset_WA, 'Weighted Approach Dataset'], [dataset_HA, 'Heuristic Approach Dataset'], [dataset_PA, 'PCA Approach Dataset']] \n",
    "\n",
    "\n",
    "# target var => y values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_HA.shape, X_train_HA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_WA.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfYMF36uRqdT"
   },
   "source": [
    "#Motivation:\n",
    "\n",
    "In the larger scope of ML algorithms, we've now determinted that the most appropriate model for our situation is the SVM. \n",
    "\n",
    "However, these models have many intricacies  that vastly change their preformance and usabilty, thus, we will further our model selection to pick the most appropriate parameters for our model.\n",
    "\n",
    "For this, we will take a \"Darwinist\" approach. By testing all these parameteres seperatly against a \"baseline\" SVM model (as defined by sklearn), and picking the best preforming one, we should be able to hypothetically create the \"best\" model for out dataset. However, there are some rammifications of not testing certain parameters together, which we will detail and talk about.\n",
    "\n",
    "The SVM parameters we are evaulation are as such:\n",
    "\n",
    "*  The type of kernel\n",
    "*  The degree for polynomial kernels\n",
    "*  The gamma kernel coefficent\n",
    "* The shrinking heuristic\n",
    "* The strength of the regularization parameter\n",
    "\n",
    "\n",
    "However, it is also worth nothing that we won't experiment with some parameters. For example, we will be using the same tolerance for stoping criterion (1e-3) as we want to keep the bound on the relative error of our models comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[2][0][0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 250886,
     "status": "ok",
     "timestamp": 1610128594782,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "SRy8j8kp0VCr"
   },
   "outputs": [],
   "source": [
    "# function used to evaluate different SVM models\n",
    "def evalModel(model, model_name, dataset, verbose = False):\n",
    "\n",
    "  # every model is evaluated against the same test dataset\n",
    "  X_train, X_test = dataset[0][0], dataset[0][1]\n",
    "  \n",
    "  #fit model\n",
    "  model.fit(X_train,y_train)\n",
    "    \n",
    "  # use the model passed as a parameter to make predictions, which we will use to judge the model \n",
    "  predicted = model.predict(X_test).round()\n",
    "\n",
    "  # metrics used here are: Accuracy, Recall, Precision, ROC/AUC and F1.\n",
    "  # these are the industry standard and provide a proper, unbiased benchmark for models.\n",
    "  accuracy_score = metrics.accuracy_score(y_test, predicted)\n",
    "  recall_score = metrics.recall_score(y_test, predicted, average='micro')\n",
    "  precision_score = metrics.precision_score(y_test, predicted, average='micro')\n",
    "  roc_auc_score = metrics.roc_auc_score(y_test, predicted, average='micro')\n",
    "  f1_score = metrics.f1_score(y_test, predicted, average='micro')\n",
    "\n",
    "  if(verbose):\n",
    "    print(\"Metrics for model name: \" + model_name + \" on \" + str(dataset[1]))\n",
    "    print(\"Accuracy score: \" + accuracy_score.astype(str))\n",
    "    print(\"Recall score: \" + recall_score.astype(str))\n",
    "    print(\"Precision_score: \" + precision_score.astype(str))\n",
    "    print(\"ROC/AUC score: \" + roc_auc_score.astype(str))\n",
    "    print(\"F1 score: \" + f1_score.astype(str))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "  # return data for sorting later\n",
    "  return [model_name,accuracy_score,recall_score,precision_score,roc_auc_score,f1_score]\n",
    "\n",
    "\n",
    "def evalMetrics(prediction, y_test):\n",
    "    \"\"\"\n",
    "    returns selected metrics of the prediction\n",
    "    \"\"\"\n",
    "    accuracy_score = metrics.accuracy_score(y_test, prediction)\n",
    "    recall_score = metrics.recall_score(y_test, prediction)\n",
    "    precision_score = metrics.precision_score(y_test, prediction)\n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, prediction)\n",
    "    f1_score = metrics.f1_score(y_test, prediction)\n",
    "    \n",
    "    print(\"Accuracy score: \" + accuracy_score.astype(str))\n",
    "    print(\"Recall score: \" + recall_score.astype(str))\n",
    "    print(\"Precision_score: \" + precision_score.astype(str))\n",
    "    print(\"ROC/AUC score: \" + roc_auc_score.astype(str))\n",
    "    print(\"F1 score: \" + f1_score.astype(str))\n",
    "    print(\"\\n\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292831,
     "status": "ok",
     "timestamp": 1610128636730,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "X8RXyMv87sj0",
    "outputId": "7a526f41-bb1c-4de2-c77b-849e4cf20e43"
   },
   "outputs": [],
   "source": [
    "# here we have our \"baseline\" SVM, as defined by sklearn. \n",
    "# let's get its preformance on each dataset to compare it to our other parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_WA.describe()\n",
    "for dataset in datasets:\n",
    "    baseline_SVM = svm.SVC()\n",
    "    evalModel(baseline_SVM, 'baseline_SVM', dataset, True);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "# define list of values for a hyperparameter\n",
    "\n",
    "datasets = datasets[1:]\n",
    "kernels = ['poly']\n",
    "k = {'kernel':kernels, 'degree': [1, 2, 3],'C': [0.1, 1, 10]}\n",
    "# define scoring metric\n",
    "scoring = ['accuracy', 'recall', 'precision', 'roc_auc', 'f1']\n",
    "\n",
    "# perform cross validation\n",
    "cv = GridSearchCV(estimator=SVC(), param_grid=k, refit='accuracy', scoring=scoring, verbose=3)\n",
    "# fit to data\n",
    "for dataset in datasets:\n",
    "    cv.fit(dataset[0][0], y_train)\n",
    "# get best estimator\n",
    "    print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training classifiers\n",
    "SVM_WA = svm.SVC(kernel='poly',degree=1, C=10)\n",
    "SVM_HA = svm.SVC(kernel='poly',degree=1, C=10)\n",
    "SVM_PA = svm.SVC(kernel='poly',degree=3, C=10)\n",
    "\n",
    "SVM_WA.fit(X_train_WA, y_train)\n",
    "SVM_HA.fit(X_train_HA, y_train)\n",
    "SVM_PA.fit(X_train_PA, y_train)\n",
    "\n",
    "y_train_WA = SVM_WA.predict(X_train_WA)\n",
    "y_train_HA = SVM_HA.predict(X_train_HA)\n",
    "y_train_PA = SVM_PA.predict(X_train_PA)\n",
    "y_train_predicted =  ((y_train_WA+y_train_HA+y_train_PA)/3).round()\n",
    "evalMetrics(y_train_predicted,y_train)\n",
    "\n",
    "y_test_WA = SVM_WA.predict(X_test_WA)\n",
    "y_test_HA = SVM_HA.predict(X_test_HA)\n",
    "y_test_PA = SVM_PA.predict(X_test_PA)\n",
    "\n",
    "#hard voting classifier consisting of the three subclassifiers\n",
    "y_predicted = ((y_test_WA+y_test_HA+y_test_PA)/3).round()\n",
    "evalMetrics(y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predicted = y_predicted \n",
    "evalMetrics(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_WA = SVM_WA.predict(X_train_WA)\n",
    "y_train_HA = SVM_HA.predict(X_train_HA)\n",
    "y_train_PA = SVM_PA.predict(X_train_PA)\n",
    "\n",
    "y_train_predicted =  ((y_train_WA+y_train_HA+y_train_PA)/3).round()\n",
    "evalMetrics(y_train_predicted,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = y_train_predicted\n",
    "evalMetrics(predicted,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = ((y_test_WA+y_test_HA+y_test_PA)/3).round()\n",
    "from sklearn.metrics import accuracy_score\n",
    "evalMetrics(y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMetrics(y_train_PA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_train_predicted, y_train))\n",
    "print(metrics.accuracy_score(y_train_predicted, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_WA = SVM_WA.predict(X_test_WA)\n",
    "y_test_HA = SVM_HA.predict(X_test_HA)\n",
    "y_test_PA = SVM_PA.predict(X_test_PA)\n",
    "\n",
    "print(accuracy_score(y_test_WA, y_test))\n",
    "print(accuracy_score(y_test_HA, y_test))\n",
    "print(accuracy_score(y_test_PA, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE-E6_o__Tge"
   },
   "source": [
    "#### Comparing the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361986,
     "status": "ok",
     "timestamp": 1610128705890,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "089SRiiH8uBq",
    "outputId": "f37aed79-dbec-425e-946d-7078d2a3fd33"
   },
   "outputs": [],
   "source": [
    "# our baseline SVM has a radial basis function kernel, so lets test the other kernel used in the algorithm\n",
    "\n",
    "# our data isn't linearly separable, so using a linear kernel isn't feasable and therefore not worth testing \n",
    "\n",
    "# SVM with a polynomial kernel (default degree = 3 )\n",
    "for dataset in datasets:\n",
    "    poly_SVM = svm.SVC(kernel=\"poly\", degree = 3)\n",
    "    evalModel(poly_SVM,\"Polynomial SVM\", dataset, True)\n",
    "\n",
    "\n",
    "# SVM with a sigmoid kernel \n",
    "for dataset in datasets:\n",
    "    sig_SVM = svm.SVC(kernel=\"sigmoid\")\n",
    "    evalModel(sig_SVM,\"Sigmoid SVM\", dataset, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsDtRKL8FRlb"
   },
   "source": [
    "Observation: \n",
    "\n",
    "The polynomial kernel SVM seems to prefrom better than the baseline radial basis function one. \n",
    "\n",
    "Whereas the Sigmoid SVM seems to preform worst in every metric compared to the 2 others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vYkKP6mcari"
   },
   "source": [
    "#Degrees for polynomial kernel\n",
    "The polynomial kernel seemed to preform well, so let's see if we can increase further the preformance of the model by fine tuning the degree of the polynomial kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510662,
     "status": "ok",
     "timestamp": 1610128854572,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "DP9X8VnWB0Ez",
    "outputId": "e179d5fa-7fe3-49b0-9566-4a93529219d1"
   },
   "outputs": [],
   "source": [
    "# our original testing with a polynomial kernel had degree 3\n",
    "# choosing and testing this is crucial. as too small a kernel will lead to underfitting and too big a kernel will lead to overfitting\n",
    "\n",
    "# here, we will test different degrees of  polynomial kerenels, from 2 to 4. \n",
    "# this range has been selected as 2 is the minimum for a polynomial funciton, and with a degree above 4, not only do training times get too long, but we risk overfitting\n",
    "# too long to train above 4\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_polynomial_kernel = []\n",
    "\n",
    "# loop to test our polynomial kernel with different degrees\n",
    "for dataset in datasets:\n",
    "    history_result = []\n",
    "    for k in range(2, 5): \n",
    "      poly_SVM = svm.SVC(kernel=\"poly\", degree = k)\n",
    "      history_result.append(evalModel(poly_SVM,\"Polynomial SVM with degree:\" + str(k), dataset, True))\n",
    "      \n",
    "    history_result_polynomial_kernel.append(history_result)\n",
    "\n",
    "\n",
    "# helper function to sort our results by accuracy \n",
    "def Sort(array): \n",
    "    # sorts a 2D array using the 2nd element (our accuracy) in descending order\n",
    "    array.sort(key = lambda x: x[1],  reverse=True) \n",
    "    return array \n",
    "\n",
    "# sort our results\n",
    "sorted_results = Sort(history_result_polynomial_kernel)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of polynomial SVMs by accuracy\")\n",
    "for result in sorted_results:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Ec9ctfdkl8"
   },
   "source": [
    "Observation: \n",
    "\n",
    "Increasing the degree of the polynomial kernel seems to ameliorate the metrics of this type of model\n",
    "\n",
    "However, we know that increasing the degree of the polynomial kernel makes our model more prone to overfitting, and thus should be considered if we were to move forwards with this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 582950,
     "status": "ok",
     "timestamp": 1610128926864,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "c2cUAoCvCQH3",
    "outputId": "36f0121c-bde7-41af-9340-7dcc750cae2d"
   },
   "outputs": [],
   "source": [
    "# the default kernel coefficent(gamma) for our SVM is \"scale\"(1 / (n_features * X.var())\n",
    "# here, we are testing \"auto\", which uses 1 / n_features\n",
    "\n",
    "# the kernel coeffiagamma kernel coefficeint for rbf, poly and sigmoid\n",
    "# first testing has gamma  =  scale, here we test for auto\n",
    "\n",
    "for dataset in dataset:\n",
    "    # baseline SVM\n",
    "    auto_baseline_SVM = svm.SVC(gamma = \"auto\")\n",
    "    evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma\", dataset, True);\n",
    "    \n",
    "    # sigmoid kernel SVM\n",
    "    auto_sig_SVM = svm.SVC(kernel=\"sigmoid\", gamma = \"auto\")\n",
    "    evalModel(auto_sig_SVM,\"sigmoid SVM with auto gamma\", dataset, True);\n",
    "\n",
    "# \"auto\" gamma and a polynomial kernel is nearly impossible to train \n",
    "# auto_poly_SVM = svm.SVC(kernel=\"poly\",gamma = \"auto\")\n",
    "# auto_poly_SVM.fit(X_train, y_train)\n",
    "# evalModel(auto_poly_SVM,\"poly SVM  with auto gamma \", True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnYvmb19DPo7"
   },
   "source": [
    "Obersvation:\n",
    "\n",
    "The results with the radial basis function are incredible in every metric. \n",
    "\n",
    "We could further hypothesise that this method would work even better with a polynomial kernel of degree 4, however the training times are too long to consider this. \n",
    "\n",
    "On the other hand, this method seems to preform very poorly with a sigmoid kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lLpNvM65S4G"
   },
   "source": [
    "#Shrinking  parameter\n",
    "This parameter is used to shorten the training time by solve the optimization problem a bit more loosely. \n",
    "\n",
    "We are testing it to see if it impacts the preformance of our models significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 754880,
     "status": "ok",
     "timestamp": 1610129098797,
     "user": {
      "displayName": "Ryan Martini",
      "photoUrl": "",
      "userId": "01591343502175491622"
     },
     "user_tz": 0
    },
    "id": "iHBfm0DvGA8Z",
    "outputId": "38e2f13d-ec9d-426e-dbf4-a19146a814de"
   },
   "outputs": [],
   "source": [
    "# test shrinking parameter, default = true\n",
    "\n",
    "# baseline rbf kernel SVM\n",
    "non_shrink_baseline_SVM = svm.SVC(shrinking = False)\n",
    "non_shrink_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_baseline_SVM,\"Baseline SVM\", True);\n",
    "\n",
    "# polynomial kernel SVM\n",
    "non_shrink_poly_SVM = svm.SVC(kernel=\"poly\",shrinking = False)\n",
    "non_shrink_poly_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_poly_SVM,\"poly SVM\", True)\n",
    "\n",
    "# sigmoid kernel SVM\n",
    "non_shrink_sig_SVM = svm.SVC(kernel=\"sigmoid\",shrinking = False)\n",
    "non_shrink_sig_SVM.fit(X_train, y_train)\n",
    "evalModel(non_shrink_sig_SVM,\"sigmoid SVM\", True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP-jOE0l99T0"
   },
   "source": [
    "Observation:\n",
    "\n",
    "The shrinking  parameter dosen't change the preformance of models significantly. \n",
    "\n",
    "As this parameter has an impact preformance, we will therefore keep it as default(True) for our final model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGhmwj1s-UJC"
   },
   "source": [
    "#Regularization parameter\n",
    "The regularization parameter is very important to avoid overfitting the model to our dataset.  The strength of the regularization is inversely proportional to C, and must be strictly positive. The penalty is a squared l2 penalty.\n",
    "\n",
    "We will test different values for this parameter and see its impact on the model preformance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw5QZybJMORx"
   },
   "outputs": [],
   "source": [
    "# all our previous models had as default the regularization parameter C =1. \n",
    "# as our C must be stricly positive, we'll test our baseline model with different values (from 2 to 8), and we should expect the accruacy to stop increasing after a point.\n",
    "\n",
    "# store the metrics of our test for sorting and concluding\n",
    "history_result_reg_param = []\n",
    "\n",
    "# loop to test our baseline with \n",
    "for n in range(1, 8): \n",
    "\n",
    "  SVM = svm.SVC(C = n)\n",
    "  SVM.fit(X_train, y_train)\n",
    "  history_result_reg_param.append(evalModel(SVM,\"baseline SVM with regularization parameter C = \" + str(n)))\n",
    "\n",
    "\n",
    "# sort our results\n",
    "sorted_results_reg = Sort(history_result_reg_param)\n",
    "\n",
    "# print our degrees in sorted order\n",
    "print(\"Sorted order of baseline SVMs by accuracy\")\n",
    "for result in sorted_results_reg:\n",
    "  print(result[0])\n",
    "  print(\"Accuracy score: \" + result[1].astype(str))\n",
    "  print(\"Recall score: \" + result[2].astype(str))\n",
    "  print(\"Precision_score: \" + result[3].astype(str))\n",
    "  print(\"ROC/AUC score: \" + result[4].astype(str))\n",
    "  print(\"F1 score: \" + result[5].astype(str))\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmZeApjF-Tab"
   },
   "source": [
    "Observation: \n",
    "\n",
    "As expected with a stronger regularization parameter, the metrics for the model are improved with a stronger regularization term, but only to a point where increasing it further  decreases the quality of the model, thus telling us that it has become overbearing. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHvJqrf0JHGU"
   },
   "source": [
    "#Conclusion\n",
    "\n",
    "Let's take our parameters and evaluate them in the context of the broader SVM model:\n",
    "\n",
    "*  The type of kernel: \n",
    "  * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "*  The degree for polynomial kernels:\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "*  The gamma kernel coefficent\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "  \n",
    "* The shrinking heuristic\n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid \n",
    "\n",
    "* The strength of the regularization \n",
    " * Best preformance by polynomial\n",
    "  * Decent by baseline\n",
    "  * Below average for sigmoid parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWTJ7MgKLIW_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\")\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma\", True);\n",
    "\n",
    "# baseline SVM\n",
    "auto_baseline_SVM = svm.SVC(gamma = \"auto\", C=4)\n",
    "auto_baseline_SVM.fit(X_train, y_train)\n",
    "evalModel(auto_baseline_SVM,\"Baseline SVM with auto gamma and reg param 4\", True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#initializing models\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=20, learning_rate=1)\n",
    "rnd_clf = RandomForestClassifier()\n",
    "log_clf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "\n",
    "for dataset in datasets:   \n",
    "    evalModel(xgb_reg, 'xgboost', dataset, True)\n",
    "    evalModel(ada_clf, 'AdaBoostClassifier', dataset, True)\n",
    "    evalModel(gbrt, 'GradientBoostingRegressor', dataset, True)\n",
    "    evalModel(rnd_clf, 'RandomForestClassifier', dataset, True)\n",
    "    evalModel(log_clf, 'LogisticRegression', dataset, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1482e948",
   "language": "python",
   "display_name": "PyCharm (CW2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}