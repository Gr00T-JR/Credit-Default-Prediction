{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64eab4c",
   "metadata": {},
   "source": [
    "# Credit Card Default Prediction Project\n",
    "\n",
    "Based on the dataset UCI Machine Learning Repository : https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "Original paper : Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
    "/Users/Jurren/Desktop/DefaultCreditCardClients_yeh_2009.pdf\n",
    "\n",
    "## Dataset Features\n",
    "* ##### 30 000 data points\n",
    "* ##### 24 attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01f931",
   "metadata": {},
   "source": [
    "## Import : Data and Libraries\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c9f5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.822020Z",
     "start_time": "2021-01-06T21:00:36.808982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import scipy.cluster.hierarchy as sch\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e17a3",
   "metadata": {},
   "source": [
    "### Import and pre-processing of dataset \n",
    "(preprocessing : transforming data into ML model readable format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports\n",
    "\n",
    "### EDIT FILEPATH IF NECESSARY\n",
    "root = '.'\n",
    "data_dir = '/DataFiles/'\n",
    "\n",
    "# form filepaths\n",
    "data_path = root + data_dir\n",
    "train_file = data_path + 'CreditCard_train.csv'\n",
    "test_file = data_path + 'CreditCard_test.csv'\n",
    "\n",
    "# load\n",
    "_df_train = pd.read_csv(train_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "_df_test = pd.read_csv(test_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "\n",
    "# create copy df for handling\n",
    "df_train = _df_train.copy()\n",
    "df_test = _df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "features = list(df_train.columns)[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "y_train = df_train['DEFAULT']\n",
    "X_train = df_train[features]\n",
    "\n",
    "y_test = df_test['DEFAULT']\n",
    "X_test = df_test[features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Checking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "            LIMIT_BAL           SEX     EDUCATION     MARRIAGE           AGE  \\\ncount    24000.000000  24000.000000  24000.000000  24000.00000  24000.000000   \nmean    165495.986667      1.628250      1.847417      1.55725     35.380458   \nstd     129128.744855      0.483282      0.780007      0.52208      9.271050   \nmin      10000.000000      1.000000      0.000000      0.00000     21.000000   \n25%      50000.000000      1.000000      1.000000      1.00000     28.000000   \n50%     140000.000000      2.000000      2.000000      2.00000     34.000000   \n75%     240000.000000      2.000000      2.000000      2.00000     41.000000   \nmax    1000000.000000      2.000000      6.000000      3.00000     79.000000   \n\n              PAY_1        PAY_2         PAY_3         PAY_4         PAY_5  \\\ncount  24000.000000  24000.00000  24000.000000  24000.000000  24000.000000   \nmean      -0.003125     -0.12350     -0.154750     -0.211667     -0.252917   \nstd        1.123425      1.20058      1.204033      1.166549      1.136993   \nmin       -2.000000     -2.00000     -2.000000     -2.000000     -2.000000   \n25%       -1.000000     -1.00000     -1.000000     -1.000000     -1.000000   \n50%        0.000000      0.00000      0.000000      0.000000      0.000000   \n75%        0.000000      0.00000      0.000000      0.000000      0.000000   \nmax        8.000000      8.00000      8.000000      8.000000      8.000000   \n\n       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\ncount  ...   24000.000000   24000.000000   24000.000000   24000.000000   \nmean   ...   42368.188417   40000.682542   38563.710625    5542.912917   \nstd    ...   63070.680934   60345.012766   59155.759799   15068.576072   \nmin    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n25%    ...    2340.000000    1740.000000    1234.750000    1000.000000   \n50%    ...   18940.500000   18107.500000   17036.000000    2100.000000   \n75%    ...   52188.500000   49746.500000   48796.250000    5000.000000   \nmax    ...  891586.000000  927171.000000  961664.000000  505000.000000   \n\n           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\ncount  2.400000e+04   24000.00000   24000.000000   24000.000000   \nmean   5.815336e+03    4969.26600    4743.480042    4783.486042   \nstd    2.079703e+04   16095.61434   14883.269990   15270.405279   \nmin    0.000000e+00       0.00000       0.000000       0.000000   \n25%    8.000000e+02     379.00000     279.750000     244.000000   \n50%    2.000000e+03    1702.50000    1500.000000    1500.000000   \n75%    5.000000e+03    4347.25000    4000.000000    4005.000000   \nmax    1.684259e+06  896040.00000  497000.000000  417990.000000   \n\n            PAY_AMT6       DEFAULT  \ncount   24000.000000  24000.000000  \nmean     5189.399042      0.223750  \nstd     17630.371990      0.416765  \nmin         0.000000      0.000000  \n25%        60.750000      0.000000  \n50%      1500.000000      0.000000  \n75%      4000.000000      0.000000  \nmax    528666.000000      1.000000  \n\n[8 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>DEFAULT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>...</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>2.400000e+04</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>165495.986667</td>\n      <td>1.628250</td>\n      <td>1.847417</td>\n      <td>1.55725</td>\n      <td>35.380458</td>\n      <td>-0.003125</td>\n      <td>-0.12350</td>\n      <td>-0.154750</td>\n      <td>-0.211667</td>\n      <td>-0.252917</td>\n      <td>...</td>\n      <td>42368.188417</td>\n      <td>40000.682542</td>\n      <td>38563.710625</td>\n      <td>5542.912917</td>\n      <td>5.815336e+03</td>\n      <td>4969.26600</td>\n      <td>4743.480042</td>\n      <td>4783.486042</td>\n      <td>5189.399042</td>\n      <td>0.223750</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>129128.744855</td>\n      <td>0.483282</td>\n      <td>0.780007</td>\n      <td>0.52208</td>\n      <td>9.271050</td>\n      <td>1.123425</td>\n      <td>1.20058</td>\n      <td>1.204033</td>\n      <td>1.166549</td>\n      <td>1.136993</td>\n      <td>...</td>\n      <td>63070.680934</td>\n      <td>60345.012766</td>\n      <td>59155.759799</td>\n      <td>15068.576072</td>\n      <td>2.079703e+04</td>\n      <td>16095.61434</td>\n      <td>14883.269990</td>\n      <td>15270.405279</td>\n      <td>17630.371990</td>\n      <td>0.416765</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10000.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>21.000000</td>\n      <td>-2.000000</td>\n      <td>-2.00000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>...</td>\n      <td>-170000.000000</td>\n      <td>-81334.000000</td>\n      <td>-339603.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>50000.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>28.000000</td>\n      <td>-1.000000</td>\n      <td>-1.00000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>2340.000000</td>\n      <td>1740.000000</td>\n      <td>1234.750000</td>\n      <td>1000.000000</td>\n      <td>8.000000e+02</td>\n      <td>379.00000</td>\n      <td>279.750000</td>\n      <td>244.000000</td>\n      <td>60.750000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>140000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>34.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>18940.500000</td>\n      <td>18107.500000</td>\n      <td>17036.000000</td>\n      <td>2100.000000</td>\n      <td>2.000000e+03</td>\n      <td>1702.50000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>240000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>41.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>52188.500000</td>\n      <td>49746.500000</td>\n      <td>48796.250000</td>\n      <td>5000.000000</td>\n      <td>5.000000e+03</td>\n      <td>4347.25000</td>\n      <td>4000.000000</td>\n      <td>4005.000000</td>\n      <td>4000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000000.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>3.00000</td>\n      <td>79.000000</td>\n      <td>8.000000</td>\n      <td>8.00000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>...</td>\n      <td>891586.000000</td>\n      <td>927171.000000</td>\n      <td>961664.000000</td>\n      <td>505000.000000</td>\n      <td>1.684259e+06</td>\n      <td>896040.00000</td>\n      <td>497000.000000</td>\n      <td>417990.000000</td>\n      <td>528666.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Comment__ : All the data types are integers and thus workable for ML models. There are no null values (arbitrarily checked and all features have the same count). Values in the `SEX`, `EDUCATION` <br>\n",
    "Optional to check the dataframes with `quick_analysis(df_train)`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "73a57eb8",
   "metadata": {},
   "source": [
    "### Benchmarking some standard ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73634e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Benchmarking.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb8cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier(eta=0.3, gamma=0.5, use_label_encoder=False)\n",
    "\n",
    "method0 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79df1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0 = method0.fit_transform(X_train)\n",
    "X_train0 = pd.DataFrame(X_train0, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b3953e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0.5,\n              gpu_id=-1, importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', use_label_encoder=False,\n              validate_parameters=1, verbosity=None)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train0,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning of ML models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML models to be optimized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "xgb_reg = xgboost.XGBRegressor(use_label_encoder=False)\n",
    "ada_reg = AdaBoostRegressor(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=20, learning_rate=1)\n",
    "log_reg = LogisticRegression(penalty = 'l1', max_iter=1000, C=0.5, solver = 'liblinear')\n",
    "svm_reg = SVC()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Hyperparameter search spaces"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from hyperopt import Trials, fmin, tpe\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from Models_spaces import space_xgb, space_ada, space_gbrt, space_log, space_svm\n",
    "from Models_objectives import objective_xgb, objective_ada, objective_gbrt, objective_log, objective_svm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': <hyperopt.pyll.base.Apply object at 0x7fdce112f2b0>, 'kernel': <hyperopt.pyll.base.Apply object at 0x7fdce112f3a0>, 'degree': <hyperopt.pyll.base.Apply object at 0x7fdce112f4f0>, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "print(space_svm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning\n",
    "\n",
    "For tuning we will be first split up the training data into a validation\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: name 'X_train_' is not defined\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-0f28c01725ad>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrials\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTrials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m best_hyperparams = fmin(fn = objective_xgb,\n\u001B[0m\u001B[1;32m      4\u001B[0m                         \u001B[0mspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspace_xgb\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                         \u001B[0malgo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtpe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuggest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mallow_trials_fmin\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fmin\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 507\u001B[0;31m         return trials.fmin(\n\u001B[0m\u001B[1;32m    508\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    680\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mfmin\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfmin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 682\u001B[0;31m         return fmin(\n\u001B[0m\u001B[1;32m    683\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    684\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[0;31m# next line is where the fmin is actually executed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m     \u001B[0mrval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    354\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, N, block_until_done)\u001B[0m\n\u001B[1;32m    290\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m                     \u001B[0;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[0;34m(self, N)\u001B[0m\n\u001B[1;32m    168\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m                     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"job exception: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[1;32m    905\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    906\u001B[0m             )\n\u001B[0;32m--> 907\u001B[0;31m             \u001B[0mrval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/GitHub/Credit-Default-Prediction/Group work/Models_objectives.py\u001B[0m in \u001B[0;36mobjective_xgb\u001B[0;34m(space)\u001B[0m\n\u001B[1;32m     19\u001B[0m     )\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mevaluation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mX_train_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m \u001B[0mX_validation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_validation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     model.fit(X_train_, y_train_,\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_' is not defined"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_xgb,\n",
    "                        space = space_xgb,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_ada,\n",
    "                        space = space_ada,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_gbrt,\n",
    "                        space = space_gbrt,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_log,\n",
    "                        space = space_log,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_svm,\n",
    "                        space = space_svm,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = method0.transform(X_test)\n",
    "X_test1 = pd.DataFrame(X_test1, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = xgb_clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model)\n",
    "plt.title(\"xgboost.plot_importance(model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"cover\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"cover\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985431",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"gain\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3afe",
   "metadata": {},
   "source": [
    "## Performance at given percentages\n",
    "### robustness\n",
    "\n",
    "As opposed to simply classifiying clients as expected to default vs not-expected to default, quantifying is more meaningful. I.e. defining a probability of default has more potential.\n",
    "\n",
    "To estimate the real probability, the Smooth Sorting Method can be used, which estimates the real probability by looking at neighboring points and taking the mean of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbabd6",
   "metadata": {},
   "source": [
    "__Smooth Sorting Method__ from the original paper (Yeh, I. C., & Lien, C. H. (2009)): \n",
    "\n",
    "$$\\text{P}_i = \\frac{\\sum_{j=-n}^{n}\\text{Y}_{i-j}}{2n+1}$$\n",
    "\n",
    "where $\\text{P}_i$ is the estimated real probability of default, $\\text{Y}_{i}$ is the binary variable of default (1) or non-default (0), $n$ is the number of data for smoothing.<br>\n",
    "The Smooth Sorting Method is used on sorted data, from the lowest probability of default occuring to the highest probability of default occuring. \n",
    "\n",
    "This is interesting to look at because loaners adopt different risk strategies.    \n",
    "(for this we "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec14761",
   "metadata": {},
   "source": [
    "we have the lists : `y_predicted` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9551f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(eta=0.3, gamma=0.5, use_label_encoder=False)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_predicted = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(y_predicted)\n",
    "\n",
    "y_test_sorted = y_test_numpy[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d2765",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "n = 200\n",
    "for counter in range(n,len(y_test_sorted)-n):\n",
    "    intermediate_val = np.mean(y_test_sorted[counter-n:counter+n])\n",
    "    y_avg.append(intermediate_val)\n",
    "    \n",
    "y_predicted_sorted = sorted(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4507880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(y_predicted[n:len(y_predicted)-n]),y_avg)\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8638e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee291ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbedc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_selected = y_predicted[n:len(y_predicted)-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6610a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_avg,y_predicted_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_predicted)-n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbc75a",
   "metadata": {},
   "source": [
    "### Explain predictions\n",
    "Tree SHAP implementation integrated into xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e06a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef44977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a minute or two since we are explaining over 30 thousand samples in a model with over a thousand trees\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d504e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28101b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[:1000,:], X.iloc[:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c64542",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bcc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "d_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ind = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c02dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values_ind = shap.TreeExplainer(model_ind).shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694592b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values_ind, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff140a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0bc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720db9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0987305a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ac58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6418ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3b82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923f726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ef3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22b441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb73a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd07050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=3)\n",
    "X_train0, y_train = sm.fit_resample(X_train0,y_train)\n",
    "# X_train0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf2 = xgboost.XGBClassifier(eta=0.1, gamma=0.5, use_label_encoder=False)\n",
    "xgb_clf2.fit(X_train0,y_train)\n",
    "y_predicted2 = xgb_clf2.predict(X_test)\n",
    "np.mean(y_predicted2==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a2c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524d213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1482e948",
   "language": "python",
   "display_name": "PyCharm (CW2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}