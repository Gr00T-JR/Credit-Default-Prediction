{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Usage of pipeline embedding samplers\n",
    "\n",
    "An example of the :class:~imblearn.pipeline.Pipeline` object (or\n",
    ":func:`~imblearn.pipeline.make_pipeline` helper function) working with\n",
    "transformers and resamplers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authors: Christos Aridas\n",
    "#          Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
    "# License: MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create an imbalanced dataset and split in to two sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_classes=2,\n",
    "    class_sep=1.25,\n",
    "    weights=[0.3, 0.7],\n",
    "    n_informative=3,\n",
    "    n_redundant=1,\n",
    "    flip_y=0,\n",
    "    n_features=5,\n",
    "    n_clusters_per_class=1,\n",
    "    n_samples=5000,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create each individual steps that we would like later to combine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "enn = EditedNearestNeighbours()\n",
    "smote = SMOTE(random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally create a pipeline to specify in which order the different\n",
    "transformers and samplers should be executed before to provide the data to\n",
    "the final classifier.\n",
    "\n",
    "For some reason, Pipeline.fit_resample does not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-1f5062ff12ec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# method0.transform(X_train)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mX_train_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod0\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;31m# np.shape(method0.fit_resample(X_train, y_train))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;31m# model = make_pipeline(pca, enn, smote, knn)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/pipeline.py\u001B[0m in \u001B[0;36m_transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    558\u001B[0m         \u001B[0mXt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 560\u001B[0;31m             \u001B[0mXt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    561\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mXt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36mtransform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m    878\u001B[0m             \u001B[0mTransformed\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m         \"\"\"\n\u001B[0;32m--> 880\u001B[0;31m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m         \u001B[0mcopy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_is_fitted\u001B[0;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[1;32m   1096\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1097\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mattrs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1098\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'name'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1099\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotFittedError\u001B[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "method0 = Pipeline([('sampling', smote),\n",
    "                    ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# X_train_new, y_train_new = method0.fit_resample(X_train, y_train)\n",
    "# method0.transform(X_train)\n",
    "\n",
    "X_train_ = method0.transform(X_train)\n",
    "# np.shape(method0.fit_resample(X_train, y_train))\n",
    "# model = make_pipeline(pca, enn, smote, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.shape(X_train)\n",
    "\n",
    "X_train_, y_train_ = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.shape(X_train_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the pipeline created as a normal classifier where resampling\n",
    "will happen when calling `fit` and disabled when calling `decision_function`,\n",
    "`predict_proba`, or `predict`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1482e948",
   "language": "python",
   "display_name": "PyCharm (CW2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}