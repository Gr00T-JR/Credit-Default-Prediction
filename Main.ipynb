{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64eab4c",
   "metadata": {},
   "source": [
    "# Credit Card Default Prediction Project\n",
    "\n",
    "Based on the dataset UCI Machine Learning Repository\n",
    "\n",
    "The original paper that works with this dataset is : Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
    "<br>__[Link to original paper](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf)__\n",
    "__[Link to UCI dataset page](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)__\n",
    "\n",
    "### Dataset Description\n",
    "* Data consists of 30 000 points and 24 attributes\n",
    "\n",
    "### Project Outline\n",
    "Data preparation and exploration -> ML models hyperparameters tuning -> Combination into a final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01f931",
   "metadata": {},
   "source": [
    "## Import : Data and Libraries\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c9f5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.822020Z",
     "start_time": "2021-01-06T21:00:36.808982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import scipy.cluster.hierarchy as sch\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e17a3",
   "metadata": {},
   "source": [
    "### Import and pre-processing of dataset \n",
    "(preprocessing : transforming data into ML model readable format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports\n",
    "\n",
    "### EDIT FILEPATH IF NECESSARY\n",
    "root = '.'\n",
    "data_dir = '/DataFiles/'\n",
    "\n",
    "# form filepaths\n",
    "data_path = root + data_dir\n",
    "train_file = data_path + 'CreditCard_train.csv'\n",
    "test_file = data_path + 'CreditCard_test.csv'\n",
    "\n",
    "# load\n",
    "_df_train = pd.read_csv(train_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "_df_test = pd.read_csv(test_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "\n",
    "# create copy df for handling\n",
    "df_train = _df_train.copy()\n",
    "df_test = _df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Checking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "            LIMIT_BAL           SEX     EDUCATION     MARRIAGE           AGE  \\\ncount    24000.000000  24000.000000  24000.000000  24000.00000  24000.000000   \nmean    165495.986667      1.628250      1.847417      1.55725     35.380458   \nstd     129128.744855      0.483282      0.780007      0.52208      9.271050   \nmin      10000.000000      1.000000      0.000000      0.00000     21.000000   \n25%      50000.000000      1.000000      1.000000      1.00000     28.000000   \n50%     140000.000000      2.000000      2.000000      2.00000     34.000000   \n75%     240000.000000      2.000000      2.000000      2.00000     41.000000   \nmax    1000000.000000      2.000000      6.000000      3.00000     79.000000   \n\n              PAY_1        PAY_2         PAY_3         PAY_4         PAY_5  \\\ncount  24000.000000  24000.00000  24000.000000  24000.000000  24000.000000   \nmean      -0.003125     -0.12350     -0.154750     -0.211667     -0.252917   \nstd        1.123425      1.20058      1.204033      1.166549      1.136993   \nmin       -2.000000     -2.00000     -2.000000     -2.000000     -2.000000   \n25%       -1.000000     -1.00000     -1.000000     -1.000000     -1.000000   \n50%        0.000000      0.00000      0.000000      0.000000      0.000000   \n75%        0.000000      0.00000      0.000000      0.000000      0.000000   \nmax        8.000000      8.00000      8.000000      8.000000      8.000000   \n\n       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\ncount  ...   24000.000000   24000.000000   24000.000000   24000.000000   \nmean   ...   42368.188417   40000.682542   38563.710625    5542.912917   \nstd    ...   63070.680934   60345.012766   59155.759799   15068.576072   \nmin    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n25%    ...    2340.000000    1740.000000    1234.750000    1000.000000   \n50%    ...   18940.500000   18107.500000   17036.000000    2100.000000   \n75%    ...   52188.500000   49746.500000   48796.250000    5000.000000   \nmax    ...  891586.000000  927171.000000  961664.000000  505000.000000   \n\n           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\ncount  2.400000e+04   24000.00000   24000.000000   24000.000000   \nmean   5.815336e+03    4969.26600    4743.480042    4783.486042   \nstd    2.079703e+04   16095.61434   14883.269990   15270.405279   \nmin    0.000000e+00       0.00000       0.000000       0.000000   \n25%    8.000000e+02     379.00000     279.750000     244.000000   \n50%    2.000000e+03    1702.50000    1500.000000    1500.000000   \n75%    5.000000e+03    4347.25000    4000.000000    4005.000000   \nmax    1.684259e+06  896040.00000  497000.000000  417990.000000   \n\n            PAY_AMT6       DEFAULT  \ncount   24000.000000  24000.000000  \nmean     5189.399042      0.223750  \nstd     17630.371990      0.416765  \nmin         0.000000      0.000000  \n25%        60.750000      0.000000  \n50%      1500.000000      0.000000  \n75%      4000.000000      0.000000  \nmax    528666.000000      1.000000  \n\n[8 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>DEFAULT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>...</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>2.400000e+04</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>165495.986667</td>\n      <td>1.628250</td>\n      <td>1.847417</td>\n      <td>1.55725</td>\n      <td>35.380458</td>\n      <td>-0.003125</td>\n      <td>-0.12350</td>\n      <td>-0.154750</td>\n      <td>-0.211667</td>\n      <td>-0.252917</td>\n      <td>...</td>\n      <td>42368.188417</td>\n      <td>40000.682542</td>\n      <td>38563.710625</td>\n      <td>5542.912917</td>\n      <td>5.815336e+03</td>\n      <td>4969.26600</td>\n      <td>4743.480042</td>\n      <td>4783.486042</td>\n      <td>5189.399042</td>\n      <td>0.223750</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>129128.744855</td>\n      <td>0.483282</td>\n      <td>0.780007</td>\n      <td>0.52208</td>\n      <td>9.271050</td>\n      <td>1.123425</td>\n      <td>1.20058</td>\n      <td>1.204033</td>\n      <td>1.166549</td>\n      <td>1.136993</td>\n      <td>...</td>\n      <td>63070.680934</td>\n      <td>60345.012766</td>\n      <td>59155.759799</td>\n      <td>15068.576072</td>\n      <td>2.079703e+04</td>\n      <td>16095.61434</td>\n      <td>14883.269990</td>\n      <td>15270.405279</td>\n      <td>17630.371990</td>\n      <td>0.416765</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10000.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>21.000000</td>\n      <td>-2.000000</td>\n      <td>-2.00000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>...</td>\n      <td>-170000.000000</td>\n      <td>-81334.000000</td>\n      <td>-339603.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>50000.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>28.000000</td>\n      <td>-1.000000</td>\n      <td>-1.00000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>2340.000000</td>\n      <td>1740.000000</td>\n      <td>1234.750000</td>\n      <td>1000.000000</td>\n      <td>8.000000e+02</td>\n      <td>379.00000</td>\n      <td>279.750000</td>\n      <td>244.000000</td>\n      <td>60.750000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>140000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>34.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>18940.500000</td>\n      <td>18107.500000</td>\n      <td>17036.000000</td>\n      <td>2100.000000</td>\n      <td>2.000000e+03</td>\n      <td>1702.50000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>240000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>41.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>52188.500000</td>\n      <td>49746.500000</td>\n      <td>48796.250000</td>\n      <td>5000.000000</td>\n      <td>5.000000e+03</td>\n      <td>4347.25000</td>\n      <td>4000.000000</td>\n      <td>4005.000000</td>\n      <td>4000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000000.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>3.00000</td>\n      <td>79.000000</td>\n      <td>8.000000</td>\n      <td>8.00000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>...</td>\n      <td>891586.000000</td>\n      <td>927171.000000</td>\n      <td>961664.000000</td>\n      <td>505000.000000</td>\n      <td>1.684259e+06</td>\n      <td>896040.00000</td>\n      <td>497000.000000</td>\n      <td>417990.000000</td>\n      <td>528666.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "features = list(df_train.columns)[:-1]\n",
    "\n",
    "# renaming columns for consistency and simplicity\n",
    "df_train = df_train.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "df_test = df_test.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "label = df_train.columns[-1]\n",
    "\n",
    "y_train = df_train[label]\n",
    "X_train = df_train[features]\n",
    "\n",
    "y_test = df_test[label]\n",
    "X_test = df_test[features]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Comment__ : All the data types are integers and thus workable for ML models. There are no null values (arbitrarily checked and all features have the same count). Values in the `SEX`, `EDUCATION` <br>\n",
    "Optional to check and explore the data further into .DataExploration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Pipeline\n",
    "* includes scaling, sampling and (future work : feature transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Dysfunctional code\n",
    "method0 = Pipeline([\n",
    "    ('sampler', SMOTE(random_state=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', None)\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_, y_train_ = SMOTE(random_state=3).fit_resample(X=X_train, y=y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train_)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "73a57eb8",
   "metadata": {},
   "source": [
    "### Benchmarking some standard ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73634e38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Checking the ML models\n",
    "* xgboost, adaboost, gradientboostingregressor, logistic regression and support vector machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning of ML models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameter tuning framework consists of a tuner (hyperopt), optimization space (model dependent), and objective function (model  dependent)\n",
    "These are imported.\n",
    "### ML models to be optimized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_validation, y_train_, y_validation = train_test_split(X_train_, y_train_, test_size = 0.25, random_state = 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Split the training data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([X_train_, y_train_, X_validation, y_validation], f)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "\n",
    "# Model hyperparameter space\n",
    "from Models_spaces import space_xgb, space_ada, space_gbrt, space_log, space_svm\n",
    "\n",
    "# Model objective function\n",
    "from Models_objectives import objective_xgb, objective_ada, objective_gbrt, objective_log, objective_svm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': <hyperopt.pyll.base.Apply object at 0x7f9493292e20>, 'kernel': <hyperopt.pyll.base.Apply object at 0x7f9493292f10>, 'degree': <hyperopt.pyll.base.Apply object at 0x7f94932990a0>, 'seed': 0}\n"
     ]
    }
   ],
   "source": [
    "print(space_svm)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning\n",
    "\n",
    "For tuning we will be first split up the training data into a validation\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: 'float' object cannot be interpreted as an integer\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-0f28c01725ad>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrials\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTrials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m best_hyperparams = fmin(fn = objective_xgb,\n\u001B[0m\u001B[1;32m      4\u001B[0m                         \u001B[0mspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspace_xgb\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                         \u001B[0malgo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtpe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuggest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mallow_trials_fmin\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fmin\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 507\u001B[0;31m         return trials.fmin(\n\u001B[0m\u001B[1;32m    508\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    680\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mfmin\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfmin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 682\u001B[0;31m         return fmin(\n\u001B[0m\u001B[1;32m    683\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    684\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[0;31m# next line is where the fmin is actually executed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m     \u001B[0mrval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    354\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, N, block_until_done)\u001B[0m\n\u001B[1;32m    290\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m                     \u001B[0;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[0;34m(self, N)\u001B[0m\n\u001B[1;32m    168\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m                     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"job exception: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[1;32m    905\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    906\u001B[0m             )\n\u001B[0;32m--> 907\u001B[0;31m             \u001B[0mrval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/GitHub/Credit-Default-Prediction/Models_objectives.py\u001B[0m in \u001B[0;36mobjective_xgb\u001B[0;34m(space)\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mevaluation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mX_train_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m \u001B[0mX_validation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_validation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m     model.fit(X_train_, y_train_,\n\u001B[0m\u001B[1;32m     29\u001B[0m             \u001B[0meval_set\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevaluation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_metric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"auc\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m             early_stopping_rounds=10,verbose=False)\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    421\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 422\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    423\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m    594\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'eval_metric'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0meval_metric\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m         self._Booster = train(params, train_dmatrix,\n\u001B[0m\u001B[1;32m    597\u001B[0m                               \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_num_boosting_rounds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevals\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m                               \u001B[0mearly_stopping_rounds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mearly_stopping_rounds\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/training.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0mBooster\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtrained\u001B[0m \u001B[0mbooster\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \"\"\"\n\u001B[0;32m--> 206\u001B[0;31m     bst = _train_internal(params, dtrain,\n\u001B[0m\u001B[1;32m    207\u001B[0m                           \u001B[0mnum_boost_round\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_boost_round\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m                           \u001B[0mevals\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevals\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/training.py\u001B[0m in \u001B[0;36m_train_internal\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m     \u001B[0mbst\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbefore_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 95\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstart_iteration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_boost_round\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbefore_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_xgb,\n",
    "                        space = space_xgb,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: __init__() got an unexpected keyword argument 'algorithm'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'algorithm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-1436165fe2d2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrials\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTrials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m best_hyperparams = fmin(fn = objective_ada,\n\u001B[0m\u001B[1;32m      4\u001B[0m                         \u001B[0mspace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspace_ada\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                         \u001B[0malgo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtpe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuggest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mallow_trials_fmin\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fmin\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 507\u001B[0;31m         return trials.fmin(\n\u001B[0m\u001B[1;32m    508\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    680\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mfmin\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfmin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 682\u001B[0;31m         return fmin(\n\u001B[0m\u001B[1;32m    683\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    684\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m     \u001B[0;31m# next line is where the fmin is actually executed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m     \u001B[0mrval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    354\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, N, block_until_done)\u001B[0m\n\u001B[1;32m    290\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m                     \u001B[0;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[0;34m(self, N)\u001B[0m\n\u001B[1;32m    168\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m                     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"job exception: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[1;32m    905\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    906\u001B[0m             )\n\u001B[0;32m--> 907\u001B[0;31m             \u001B[0mrval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/GitHub/Credit-Default-Prediction/Models_objectives.py\u001B[0m in \u001B[0;36mobjective_ada\u001B[0;34m(space)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mobjective_ada\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m     model = AdaBoostRegressor(\n\u001B[0m\u001B[1;32m     41\u001B[0m         \u001B[0malgorithm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspace\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'algorithm'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mspace\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'learning_rate'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'algorithm'"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_ada,\n",
    "                        space = space_ada,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_gbrt,\n",
    "                        space = space_gbrt,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_log,\n",
    "                        space = space_log,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_svm,\n",
    "                        space = space_svm,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = method0.transform(X_test)\n",
    "X_test1 = pd.DataFrame(X_test1, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = xgb_clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model)\n",
    "plt.title(\"xgboost.plot_importance(model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"cover\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"cover\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985431",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"gain\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3afe",
   "metadata": {},
   "source": [
    "## Performance at given percentages\n",
    "### robustness\n",
    "\n",
    "As opposed to simply classifiying clients as expected to default vs not-expected to default, quantifying is more meaningful. I.e. defining a probability of default has more potential.\n",
    "\n",
    "To estimate the real probability, the Smooth Sorting Method can be used, which estimates the real probability by looking at neighboring points and taking the mean of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbabd6",
   "metadata": {},
   "source": [
    "__Smooth Sorting Method__ from the original paper (Yeh, I. C., & Lien, C. H. (2009)): \n",
    "\n",
    "$$\\text{P}_i = \\frac{\\sum_{j=-n}^{n}\\text{Y}_{i-j}}{2n+1}$$\n",
    "\n",
    "where $\\text{P}_i$ is the estimated real probability of default, $\\text{Y}_{i}$ is the binary variable of default (1) or non-default (0), $n$ is the number of data for smoothing.<br>\n",
    "The Smooth Sorting Method is used on sorted data, from the lowest probability of default occuring to the highest probability of default occuring. \n",
    "\n",
    "This is interesting to look at because loaners adopt different risk strategies.    \n",
    "(for this we "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec14761",
   "metadata": {},
   "source": [
    "we have the lists : `y_predicted` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9551f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(eta=0.3, gamma=0.5, use_label_encoder=False)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_predicted = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(y_predicted)\n",
    "\n",
    "y_test_sorted = y_test_numpy[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d2765",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "n = 200\n",
    "for counter in range(n,len(y_test_sorted)-n):\n",
    "    intermediate_val = np.mean(y_test_sorted[counter-n:counter+n])\n",
    "    y_avg.append(intermediate_val)\n",
    "    \n",
    "y_predicted_sorted = sorted(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4507880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(y_predicted[n:len(y_predicted)-n]),y_avg)\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8638e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee291ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbedc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_selected = y_predicted[n:len(y_predicted)-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6610a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_avg,y_predicted_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c73b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(y_predicted)-n\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1482e948",
   "language": "python",
   "display_name": "PyCharm (CW2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}