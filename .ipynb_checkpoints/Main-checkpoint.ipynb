{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64eab4c",
   "metadata": {},
   "source": [
    "# Credit Card Default Prediction Project\n",
    "\n",
    "Based on the dataset UCI Machine Learning Repository\n",
    "\n",
    "The original paper that works with this dataset is : Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
    "<br>__[Link to original paper](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf)__\n",
    "__[Link to UCI dataset page](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)__\n",
    "\n",
    "### Dataset Description\n",
    "* Data consists of 30 000 points and 24 attributes\n",
    "\n",
    "### Project Outline\n",
    "Data preparation and exploration -> ML models hyperparameters tuning -> Combination into a final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01f931",
   "metadata": {},
   "source": [
    "## Import : Data and Libraries\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c9f5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.822020Z",
     "start_time": "2021-01-06T21:00:36.808982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import scipy.cluster.hierarchy as sch\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e17a3",
   "metadata": {},
   "source": [
    "### Import and pre-processing of dataset \n",
    "(preprocessing : transforming data into ML model readable format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports\n",
    "\n",
    "### EDIT FILEPATH IF NECESSARY\n",
    "root = '.'\n",
    "data_dir = '/DataFiles/'\n",
    "\n",
    "# form filepaths\n",
    "data_path = root + data_dir\n",
    "train_file = data_path + 'CreditCard_train.csv'\n",
    "test_file = data_path + 'CreditCard_test.csv'\n",
    "\n",
    "# load\n",
    "_df_train = pd.read_csv(train_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "_df_test = pd.read_csv(test_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "\n",
    "# create copy df for handling\n",
    "df_train = _df_train.copy()\n",
    "df_test = _df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc5862",
   "metadata": {},
   "source": [
    "### Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed37f0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.00000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.00000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>2.400000e+04</td>\n",
       "      <td>24000.00000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165495.986667</td>\n",
       "      <td>1.628250</td>\n",
       "      <td>1.847417</td>\n",
       "      <td>1.55725</td>\n",
       "      <td>35.380458</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.12350</td>\n",
       "      <td>-0.154750</td>\n",
       "      <td>-0.211667</td>\n",
       "      <td>-0.252917</td>\n",
       "      <td>...</td>\n",
       "      <td>42368.188417</td>\n",
       "      <td>40000.682542</td>\n",
       "      <td>38563.710625</td>\n",
       "      <td>5542.912917</td>\n",
       "      <td>5.815336e+03</td>\n",
       "      <td>4969.26600</td>\n",
       "      <td>4743.480042</td>\n",
       "      <td>4783.486042</td>\n",
       "      <td>5189.399042</td>\n",
       "      <td>0.223750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129128.744855</td>\n",
       "      <td>0.483282</td>\n",
       "      <td>0.780007</td>\n",
       "      <td>0.52208</td>\n",
       "      <td>9.271050</td>\n",
       "      <td>1.123425</td>\n",
       "      <td>1.20058</td>\n",
       "      <td>1.204033</td>\n",
       "      <td>1.166549</td>\n",
       "      <td>1.136993</td>\n",
       "      <td>...</td>\n",
       "      <td>63070.680934</td>\n",
       "      <td>60345.012766</td>\n",
       "      <td>59155.759799</td>\n",
       "      <td>15068.576072</td>\n",
       "      <td>2.079703e+04</td>\n",
       "      <td>16095.61434</td>\n",
       "      <td>14883.269990</td>\n",
       "      <td>15270.405279</td>\n",
       "      <td>17630.371990</td>\n",
       "      <td>0.416765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>1234.750000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>379.00000</td>\n",
       "      <td>279.750000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18940.500000</td>\n",
       "      <td>18107.500000</td>\n",
       "      <td>17036.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>1702.50000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52188.500000</td>\n",
       "      <td>49746.500000</td>\n",
       "      <td>48796.250000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4347.25000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4005.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>505000.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>497000.000000</td>\n",
       "      <td>417990.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LIMIT_BAL           SEX     EDUCATION     MARRIAGE           AGE  \\\n",
       "count    24000.000000  24000.000000  24000.000000  24000.00000  24000.000000   \n",
       "mean    165495.986667      1.628250      1.847417      1.55725     35.380458   \n",
       "std     129128.744855      0.483282      0.780007      0.52208      9.271050   \n",
       "min      10000.000000      1.000000      0.000000      0.00000     21.000000   \n",
       "25%      50000.000000      1.000000      1.000000      1.00000     28.000000   \n",
       "50%     140000.000000      2.000000      2.000000      2.00000     34.000000   \n",
       "75%     240000.000000      2.000000      2.000000      2.00000     41.000000   \n",
       "max    1000000.000000      2.000000      6.000000      3.00000     79.000000   \n",
       "\n",
       "              PAY_1        PAY_2         PAY_3         PAY_4         PAY_5  \\\n",
       "count  24000.000000  24000.00000  24000.000000  24000.000000  24000.000000   \n",
       "mean      -0.003125     -0.12350     -0.154750     -0.211667     -0.252917   \n",
       "std        1.123425      1.20058      1.204033      1.166549      1.136993   \n",
       "min       -2.000000     -2.00000     -2.000000     -2.000000     -2.000000   \n",
       "25%       -1.000000     -1.00000     -1.000000     -1.000000     -1.000000   \n",
       "50%        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "max        8.000000      8.00000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   24000.000000   24000.000000   24000.000000   24000.000000   \n",
       "mean   ...   42368.188417   40000.682542   38563.710625    5542.912917   \n",
       "std    ...   63070.680934   60345.012766   59155.759799   15068.576072   \n",
       "min    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n",
       "25%    ...    2340.000000    1740.000000    1234.750000    1000.000000   \n",
       "50%    ...   18940.500000   18107.500000   17036.000000    2100.000000   \n",
       "75%    ...   52188.500000   49746.500000   48796.250000    5000.000000   \n",
       "max    ...  891586.000000  927171.000000  961664.000000  505000.000000   \n",
       "\n",
       "           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  2.400000e+04   24000.00000   24000.000000   24000.000000   \n",
       "mean   5.815336e+03    4969.26600    4743.480042    4783.486042   \n",
       "std    2.079703e+04   16095.61434   14883.269990   15270.405279   \n",
       "min    0.000000e+00       0.00000       0.000000       0.000000   \n",
       "25%    8.000000e+02     379.00000     279.750000     244.000000   \n",
       "50%    2.000000e+03    1702.50000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4347.25000    4000.000000    4005.000000   \n",
       "max    1.684259e+06  896040.00000  497000.000000  417990.000000   \n",
       "\n",
       "            PAY_AMT6       DEFAULT  \n",
       "count   24000.000000  24000.000000  \n",
       "mean     5189.399042      0.223750  \n",
       "std     17630.371990      0.416765  \n",
       "min         0.000000      0.000000  \n",
       "25%        60.750000      0.000000  \n",
       "50%      1500.000000      0.000000  \n",
       "75%      4000.000000      0.000000  \n",
       "max    528666.000000      1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118dbadd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = list(df_train.columns)[:-1]\n",
    "\n",
    "# renaming columns for consistency and simplicity\n",
    "df_train = df_train.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "df_test = df_test.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "label = df_train.columns[-1]\n",
    "\n",
    "y_train = df_train[label]\n",
    "X_train = df_train[features]\n",
    "\n",
    "y_test = df_test[label]\n",
    "X_test = df_test[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b9cb1",
   "metadata": {},
   "source": [
    "__Comment__ : All the data types are integers and thus workable for ML models. There are no null values (arbitrarily checked and all features have the same count). Values in the `SEX`, `EDUCATION` <br>\n",
    "Optional to check and explore the data further into .DataExploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b71d61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Pipeline\n",
    "* includes scaling, sampling and (future work : feature transformation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "179757df",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Dysfunctional code\n",
    "method0 = Pipeline([\n",
    "    ('sampler', SMOTE(random_state=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', None)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2a0496",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_, y_train_ = SMOTE(random_state=3).fit_resample(X=X_train, y=y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_ = scaler.fit_transform(X_train_)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a57eb8",
   "metadata": {},
   "source": [
    "### Benchmarking some standard ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73634e38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Checking the ML models\n",
    "* xgboost, adaboost, gradientboostingregressor, logistic regression and support vector machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9031e35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameter tuning of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3f108",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameter tuning framework consists of a tuner (hyperopt), optimization space (model dependent), and objective function (model  dependent)\n",
    "These are imported.\n",
    "### ML models to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ede8af",
   "metadata": {
    "pycharm": {
     "name": "#%% Split the training data\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_validation, y_train_, y_validation = train_test_split(X_train_, y_train_, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938c38cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([X_train_, y_train_, X_validation, y_validation], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a580e263",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "\n",
    "# Model hyperparameter space\n",
    "from Models_spaces import space_xgb, space_ada, space_gbrt, space_log, space_svm\n",
    "\n",
    "# Model objective function\n",
    "from Models_objectives import objective_xgb, objective_ada, objective_gbrt, objective_log, objective_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4faa55",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tuning\n",
    "\n",
    "For tuning we will be first split up the training data into a validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87235b65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_gbrt,\n",
    "                        space = space_gbrt,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 10,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a66ae38",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                \n",
      "0.7572732152442297                                    \n",
      "SCORE:                                                                           \n",
      "0.7450348899624262                                                               \n",
      "SCORE:                                                                           \n",
      "0.7539452495974235                                                               \n",
      "SCORE:                                                                           \n",
      "0.7533011272141706                                                               \n",
      "SCORE:                                                                           \n",
      "0.7588835212023618                                                               \n",
      "SCORE:                                                                           \n",
      "0.7494363929146538                                                               \n",
      "SCORE:                                                                           \n",
      "0.7524422973698336                                                               \n",
      "SCORE:                                                                           \n",
      "0.7565217391304347                                                               \n",
      "SCORE:                                                                           \n",
      "0.7641438539989265                                                               \n",
      "SCORE:                                                                           \n",
      "0.7651100375738057                                                               \n",
      "SCORE:                                                                            \n",
      "0.7501878690284487                                                                \n",
      "SCORE:                                                                            \n",
      "0.7549114331723027                                                                \n",
      "SCORE:                                                                            \n",
      "0.7623188405797101                                                                \n",
      "SCORE:                                                                            \n",
      "0.7525496511003757                                                                \n",
      "SCORE:                                                                            \n",
      "0.7565217391304347                                                                \n",
      "SCORE:                                                                            \n",
      "0.7581320450885668                                                                \n",
      "SCORE:                                                                            \n",
      "0.7460010735373054                                                                \n",
      "SCORE:                                                                            \n",
      "0.7594202898550725                                                                \n",
      "SCORE:                                                                            \n",
      "0.7560923242082662                                                                \n",
      "SCORE:                                                                            \n",
      "0.7578099838969404                                                                \n",
      "SCORE:                                                                            \n",
      "0.7672571121846484                                                                \n",
      "SCORE:                                                                            \n",
      "0.7669350509930221                                                                \n",
      "SCORE:                                                                            \n",
      "0.7681159420289855                                                                \n",
      "SCORE:                                                                            \n",
      "0.7628556092324208                                                                \n",
      "SCORE:                                                                            \n",
      "0.7621041331186259                                                                \n",
      "SCORE:                                                                            \n",
      "0.7561996779388084                                                                \n",
      "SCORE:                                                                            \n",
      "0.7697262479871175                                                                \n",
      "SCORE:                                                                            \n",
      "0.7698336017176597                                                                \n",
      "SCORE:                                                                            \n",
      "0.7720880300590446                                                                \n",
      "SCORE:                                                                            \n",
      "0.7717659688674181                                                                \n",
      "SCORE:                                                                            \n",
      "0.7688674181427805                                                                \n",
      "SCORE:                                                                            \n",
      "0.760601180891036                                                                 \n",
      "SCORE:                                                                            \n",
      "0.7604938271604939                                                                \n",
      "SCORE:                                                                            \n",
      "0.7713365539452496                                                                \n",
      "SCORE:                                                                            \n",
      "0.7587761674718196                                                                \n",
      "SCORE:                                                                            \n",
      "0.7643585614600107                                                                \n",
      "SCORE:                                                                            \n",
      "0.745679012345679                                                                 \n",
      "SCORE:                                                                            \n",
      "0.7552334943639292                                                                \n",
      "SCORE:                                                                            \n",
      "0.7712292002147074                                                                \n",
      "SCORE:                                                                            \n",
      "0.7508319914117015                                                                \n",
      "SCORE:                                                                            \n",
      "0.7548040794417606                                                                \n",
      "SCORE:                                                                            \n",
      "0.7633923778851315                                                                \n",
      "SCORE:                                                                            \n",
      "0.7436392914653784                                                                \n",
      "SCORE:                                                                            \n",
      "0.7573805689747719                                                                \n",
      "SCORE:                                                                            \n",
      "0.7581320450885668                                                                \n",
      "SCORE:                                                                            \n",
      "0.7559849704777241                                                                \n",
      "SCORE:                                                                            \n",
      "0.7563070316693505                                                                \n",
      "SCORE:                                                                            \n",
      "0.7670424047235641                                                                \n",
      "SCORE:                                                                            \n",
      "0.7514761137949544                                                                \n",
      "SCORE:                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7695115405260333                                                                \n",
      "100%|██████████| 50/50 [01:46<00:00,  2.13s/trial, best loss: -0.7720880300590446]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.7365073567798435, 'gamma': 1.7091131280618583, 'learning_rate': 0.1935108193359025, 'max_depth': 6.0, 'min_child_weight': 5.0, 'n_estimators': 46.0, 'reg_alpha': 67.0, 'reg_lambda': 0.21043839019747082}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_xgb,\n",
    "                        space = space_xgb,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc212fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[19:55:28] /Users/travis/build/dmlc/xgboost/src/objective/objective.cc:26: Unknown objective function: `{'colsample_bytree': 0.7365073567798435, 'gamma': 1.7091131280618583, 'learning_rate': 0.1935108193359025, 'max_depth': 6.0, 'min_child_weight': 5.0, 'n_estimators': 46.0, 'reg_alpha': 67.0, 'reg_lambda': 0.21043839019747082}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000121dab170 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n  [bt] (1) 2   libxgboost.dylib                    0x0000000121e9f33a xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 778\n  [bt] (2) 3   libxgboost.dylib                    0x0000000121e62032 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 2082\n  [bt] (3) 4   libxgboost.dylib                    0x0000000121e56468 xgboost::LearnerConfiguration::Configure() + 1416\n  [bt] (4) 5   libxgboost.dylib                    0x0000000121e56968 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 120\n  [bt] (5) 6   libxgboost.dylib                    0x0000000121da08dc XGBoosterUpdateOneIter + 156\n  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000103a2af17 ffi_call_unix64 + 79\n  [bt] (7) 8   ???                                 0x00007ffeecc0ec90 0x0 + 140732870487184\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7735cdfcca54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxgb_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg:squarederror'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxgb_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m pred = xgb_reg.predictt(X_train_, y_train_,\n\u001b[1;32m      5\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    597\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \"\"\"\n\u001b[0;32m--> 206\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    207\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [19:55:28] /Users/travis/build/dmlc/xgboost/src/objective/objective.cc:26: Unknown objective function: `{'colsample_bytree': 0.7365073567798435, 'gamma': 1.7091131280618583, 'learning_rate': 0.1935108193359025, 'max_depth': 6.0, 'min_child_weight': 5.0, 'n_estimators': 46.0, 'reg_alpha': 67.0, 'reg_lambda': 0.21043839019747082}`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: reg:pseudohubererror\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000121dab170 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n  [bt] (1) 2   libxgboost.dylib                    0x0000000121e9f33a xgboost::ObjFunction::Create(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, xgboost::GenericParameter const*) + 778\n  [bt] (2) 3   libxgboost.dylib                    0x0000000121e62032 xgboost::LearnerConfiguration::ConfigureObjective(xgboost::LearnerTrainParam const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > >*) + 2082\n  [bt] (3) 4   libxgboost.dylib                    0x0000000121e56468 xgboost::LearnerConfiguration::Configure() + 1416\n  [bt] (4) 5   libxgboost.dylib                    0x0000000121e56968 xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 120\n  [bt] (5) 6   libxgboost.dylib                    0x0000000121da08dc XGBoosterUpdateOneIter + 156\n  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000103a2af17 ffi_call_unix64 + 79\n  [bt] (7) 8   ???                                 0x00007ffeecc0ec90 0x0 + 140732870487184\n\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "best_hyperparams['objective'] = 'reg:squarederror'\n",
    "xgb_reg = xgb.XGBRegressor(best_hyperparams, objective='reg:squarederror')\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "pred = xgb_reg.predictt(X_train_, y_train_,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157d55f",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_ada,\n",
    "                        space = space_ada,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd22aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_log,\n",
    "                        space = space_log,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e87f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_svm,\n",
    "                        space = space_svm,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = method0.transform(X_test)\n",
    "X_test1 = pd.DataFrame(X_test1, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = xgb_clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model)\n",
    "plt.title(\"xgboost.plot_importance(model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"cover\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"cover\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985431",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"gain\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3afe",
   "metadata": {},
   "source": [
    "## Performance at given percentages\n",
    "### robustness\n",
    "\n",
    "As opposed to simply classifiying clients as expected to default vs not-expected to default, quantifying is more meaningful. I.e. defining a probability of default has more potential.\n",
    "\n",
    "To estimate the real probability, the Smooth Sorting Method can be used, which estimates the real probability by looking at neighboring points and taking the mean of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbabd6",
   "metadata": {},
   "source": [
    "__Smooth Sorting Method__ from the original paper (Yeh, I. C., & Lien, C. H. (2009)): \n",
    "\n",
    "$$\\text{P}_i = \\frac{\\sum_{j=-n}^{n}\\text{Y}_{i-j}}{2n+1}$$\n",
    "\n",
    "where $\\text{P}_i$ is the estimated real probability of default, $\\text{Y}_{i}$ is the binary variable of default (1) or non-default (0), $n$ is the number of data for smoothing.<br>\n",
    "The Smooth Sorting Method is used on sorted data, from the lowest probability of default occuring to the highest probability of default occuring. \n",
    "\n",
    "This is interesting to look at because loaners adopt different risk strategies.    \n",
    "(for this we "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec14761",
   "metadata": {},
   "source": [
    "we have the lists : `y_predicted` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9551f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(eta=0.3, gamma=0.5, use_label_encoder=False)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_predicted = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(y_predicted)\n",
    "\n",
    "y_test_sorted = y_test_numpy[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d2765",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "n = 200\n",
    "for counter in range(n,len(y_test_sorted)-n):\n",
    "    intermediate_val = np.mean(y_test_sorted[counter-n:counter+n])\n",
    "    y_avg.append(intermediate_val)\n",
    "    \n",
    "y_predicted_sorted = sorted(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4507880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(y_predicted[n:len(y_predicted)-n]),y_avg)\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8638e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee291ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbedc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_selected = y_predicted[n:len(y_predicted)-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6610a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_avg,y_predicted_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c73b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(y_predicted)-n\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CW2)",
   "language": "python",
   "name": "pycharm-1482e948"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
