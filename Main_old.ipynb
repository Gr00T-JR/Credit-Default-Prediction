{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64eab4c",
   "metadata": {},
   "source": [
    "# Credit Card Default Prediction Project\n",
    "\n",
    "Based on the dataset UCI Machine Learning Repository\n",
    "\n",
    "The original paper that works with this dataset is : Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
    "<br>__[Link to original paper](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf)__\n",
    "__[Link to UCI dataset page](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)__\n",
    "\n",
    "### Dataset Description\n",
    "* Data consists of 30 000 points and 24 attributes\n",
    "\n",
    "### Project Outline\n",
    "Data preparation and exploration -> ML models hyperparameters tuning -> Combination into a final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01f931",
   "metadata": {},
   "source": [
    "## Import : Data and Libraries\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c9f5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T21:00:38.822020Z",
     "start_time": "2021-01-06T21:00:36.808982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import scipy.cluster.hierarchy as sch\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e17a3",
   "metadata": {},
   "source": [
    "### Import and pre-processing of dataset \n",
    "(preprocessing : transforming data into ML model readable format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports\n",
    "\n",
    "### EDIT FILEPATH IF NECESSARY\n",
    "root = '.'\n",
    "data_dir = '/DataFiles/'\n",
    "\n",
    "# form filepaths\n",
    "data_path = root + data_dir\n",
    "train_file = data_path + 'CreditCard_train.csv'\n",
    "test_file = data_path + 'CreditCard_test.csv'\n",
    "\n",
    "# load\n",
    "_df_train = pd.read_csv(train_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "_df_test = pd.read_csv(test_file, index_col=0, header=1).rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "\n",
    "# create copy df for handling\n",
    "df_train = _df_train.copy()\n",
    "df_test = _df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc5862",
   "metadata": {},
   "source": [
    "### Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed37f0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            LIMIT_BAL           SEX     EDUCATION     MARRIAGE           AGE  \\\ncount    24000.000000  24000.000000  24000.000000  24000.00000  24000.000000   \nmean    165495.986667      1.628250      1.847417      1.55725     35.380458   \nstd     129128.744855      0.483282      0.780007      0.52208      9.271050   \nmin      10000.000000      1.000000      0.000000      0.00000     21.000000   \n25%      50000.000000      1.000000      1.000000      1.00000     28.000000   \n50%     140000.000000      2.000000      2.000000      2.00000     34.000000   \n75%     240000.000000      2.000000      2.000000      2.00000     41.000000   \nmax    1000000.000000      2.000000      6.000000      3.00000     79.000000   \n\n              PAY_1        PAY_2         PAY_3         PAY_4         PAY_5  \\\ncount  24000.000000  24000.00000  24000.000000  24000.000000  24000.000000   \nmean      -0.003125     -0.12350     -0.154750     -0.211667     -0.252917   \nstd        1.123425      1.20058      1.204033      1.166549      1.136993   \nmin       -2.000000     -2.00000     -2.000000     -2.000000     -2.000000   \n25%       -1.000000     -1.00000     -1.000000     -1.000000     -1.000000   \n50%        0.000000      0.00000      0.000000      0.000000      0.000000   \n75%        0.000000      0.00000      0.000000      0.000000      0.000000   \nmax        8.000000      8.00000      8.000000      8.000000      8.000000   \n\n       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\ncount  ...   24000.000000   24000.000000   24000.000000   24000.000000   \nmean   ...   42368.188417   40000.682542   38563.710625    5542.912917   \nstd    ...   63070.680934   60345.012766   59155.759799   15068.576072   \nmin    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n25%    ...    2340.000000    1740.000000    1234.750000    1000.000000   \n50%    ...   18940.500000   18107.500000   17036.000000    2100.000000   \n75%    ...   52188.500000   49746.500000   48796.250000    5000.000000   \nmax    ...  891586.000000  927171.000000  961664.000000  505000.000000   \n\n           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\ncount  2.400000e+04   24000.00000   24000.000000   24000.000000   \nmean   5.815336e+03    4969.26600    4743.480042    4783.486042   \nstd    2.079703e+04   16095.61434   14883.269990   15270.405279   \nmin    0.000000e+00       0.00000       0.000000       0.000000   \n25%    8.000000e+02     379.00000     279.750000     244.000000   \n50%    2.000000e+03    1702.50000    1500.000000    1500.000000   \n75%    5.000000e+03    4347.25000    4000.000000    4005.000000   \nmax    1.684259e+06  896040.00000  497000.000000  417990.000000   \n\n            PAY_AMT6       DEFAULT  \ncount   24000.000000  24000.000000  \nmean     5189.399042      0.223750  \nstd     17630.371990      0.416765  \nmin         0.000000      0.000000  \n25%        60.750000      0.000000  \n50%      1500.000000      0.000000  \n75%      4000.000000      0.000000  \nmax    528666.000000      1.000000  \n\n[8 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_1</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>DEFAULT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>...</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>2.400000e+04</td>\n      <td>24000.00000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n      <td>24000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>165495.986667</td>\n      <td>1.628250</td>\n      <td>1.847417</td>\n      <td>1.55725</td>\n      <td>35.380458</td>\n      <td>-0.003125</td>\n      <td>-0.12350</td>\n      <td>-0.154750</td>\n      <td>-0.211667</td>\n      <td>-0.252917</td>\n      <td>...</td>\n      <td>42368.188417</td>\n      <td>40000.682542</td>\n      <td>38563.710625</td>\n      <td>5542.912917</td>\n      <td>5.815336e+03</td>\n      <td>4969.26600</td>\n      <td>4743.480042</td>\n      <td>4783.486042</td>\n      <td>5189.399042</td>\n      <td>0.223750</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>129128.744855</td>\n      <td>0.483282</td>\n      <td>0.780007</td>\n      <td>0.52208</td>\n      <td>9.271050</td>\n      <td>1.123425</td>\n      <td>1.20058</td>\n      <td>1.204033</td>\n      <td>1.166549</td>\n      <td>1.136993</td>\n      <td>...</td>\n      <td>63070.680934</td>\n      <td>60345.012766</td>\n      <td>59155.759799</td>\n      <td>15068.576072</td>\n      <td>2.079703e+04</td>\n      <td>16095.61434</td>\n      <td>14883.269990</td>\n      <td>15270.405279</td>\n      <td>17630.371990</td>\n      <td>0.416765</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10000.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>21.000000</td>\n      <td>-2.000000</td>\n      <td>-2.00000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>-2.000000</td>\n      <td>...</td>\n      <td>-170000.000000</td>\n      <td>-81334.000000</td>\n      <td>-339603.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>50000.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>28.000000</td>\n      <td>-1.000000</td>\n      <td>-1.00000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>2340.000000</td>\n      <td>1740.000000</td>\n      <td>1234.750000</td>\n      <td>1000.000000</td>\n      <td>8.000000e+02</td>\n      <td>379.00000</td>\n      <td>279.750000</td>\n      <td>244.000000</td>\n      <td>60.750000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>140000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>34.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>18940.500000</td>\n      <td>18107.500000</td>\n      <td>17036.000000</td>\n      <td>2100.000000</td>\n      <td>2.000000e+03</td>\n      <td>1702.50000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>1500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>240000.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n      <td>41.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>52188.500000</td>\n      <td>49746.500000</td>\n      <td>48796.250000</td>\n      <td>5000.000000</td>\n      <td>5.000000e+03</td>\n      <td>4347.25000</td>\n      <td>4000.000000</td>\n      <td>4005.000000</td>\n      <td>4000.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1000000.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>3.00000</td>\n      <td>79.000000</td>\n      <td>8.000000</td>\n      <td>8.00000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>...</td>\n      <td>891586.000000</td>\n      <td>927171.000000</td>\n      <td>961664.000000</td>\n      <td>505000.000000</td>\n      <td>1.684259e+06</td>\n      <td>896040.00000</td>\n      <td>497000.000000</td>\n      <td>417990.000000</td>\n      <td>528666.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118dbadd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = list(df_train.columns)[:-1]\n",
    "\n",
    "# renaming columns for consistency and simplicity\n",
    "df_train = df_train.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "df_test = df_test.rename(columns={'PAY_0':'PAY_1', 'default payment next month':'DEFAULT'})\n",
    "label = df_train.columns[-1]\n",
    "\n",
    "y_train = df_train[label]\n",
    "X_train = df_train[features]\n",
    "\n",
    "y_test = df_test[label]\n",
    "X_test = df_test[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b9cb1",
   "metadata": {},
   "source": [
    "__Comment__ : All the data types are integers and thus workable for ML models. There are no null values (arbitrarily checked and all features have the same count). Values in the `SEX`, `EDUCATION` <br>\n",
    "Optional to check and explore the data further into .DataExploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b71d61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Pipeline\n",
    "* includes scaling, sampling and (future work : feature transformation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "179757df",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Dysfunctional code\n",
    "method0 = Pipeline([\n",
    "    ('sampler', SMOTE(random_state=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', None)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2a0496",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# X_train_, y_train_ = SMOTE(random_state=3).fit_resample(X=X_train, y=y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_, y_train_ = scaler.fit_transform(X_train), y_train\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a57eb8",
   "metadata": {},
   "source": [
    "### Benchmarking some standard ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73634e38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Checking the ML models\n",
    "* xgboost, adaboost, gradientboostingregressor, logistic regression and support vector machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9031e35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameter tuning of ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3f108",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hyperparameter tuning framework consists of a tuner (hyperopt), optimization space (model dependent), and objective function (model  dependent)\n",
    "These are imported.\n",
    "### ML models to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ede8af",
   "metadata": {
    "pycharm": {
     "name": "#%% Split the training data\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_validation, y_train_, y_validation = train_test_split(X_train_, y_train_, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938c38cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([X_train_, y_train_, X_validation, y_validation], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a580e263",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "from hyperopt import Trials, fmin, tpe\n",
    "\n",
    "# Model hyperparameter space\n",
    "from Models_spaces import space_xgb, space_ada, space_gbrt, space_log, space_svm\n",
    "\n",
    "# Model objective function\n",
    "from Models_objectives import objective_xgb, objective_ada, objective_gbrt, objective_log, objective_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4faa55",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tuning\n",
    "\n",
    "For tuning we will be first split up the training data into a validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87235b65",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_gbrt,\n",
    "                        space = space_gbrt,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 10,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a66ae38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "source": [
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_xgb,\n",
    "                        space = space_xgb,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n",
    "\n"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                \n",
      "0.778                                                 \n",
      "SCORE:                                                              \n",
      "0.8046666666666666                                                  \n",
      "SCORE:                                                                           \n",
      "0.806                                                                            \n",
      "SCORE:                                                                           \n",
      "0.8046666666666666                                                  \n",
      "SCORE:                                                              \n",
      "0.8045                                                              \n",
      "SCORE:                                                              \n",
      "0.8063333333333333                                                  \n",
      "SCORE:                                                                           \n",
      "0.7831666666666667                                                               \n",
      "SCORE:                                                                           \n",
      "0.7838333333333334                                                               \n",
      "SCORE:                                                                           \n",
      "0.8033333333333333                                                               \n",
      "SCORE:                                                                           \n",
      "0.778                                                                            \n",
      "SCORE:                                                                            \n",
      "0.7871666666666667                                                                \n",
      "SCORE:                                                                            \n",
      "0.8046666666666666                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8045                                                                            \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8068333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8046666666666666                                                                \n",
      "SCORE:                                                                            \n",
      "0.8065                                                                            \n",
      "SCORE:                                                                            \n",
      "0.798                                                                             \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8043333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8058333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8046666666666666                                                                \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8033333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8073333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8046666666666666                                                                \n",
      "SCORE:                                                                            \n",
      "0.8073333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8058333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8016666666666666                                                                \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.8048333333333333                                                                \n",
      "SCORE:                                                                            \n",
      "0.809                                                                             \n",
      "SCORE:                                                                            \n",
      "0.8108333333333333                                                                \n",
      "100%|██████████| 50/50 [00:25<00:00,  1.97trial/s, best loss: -0.8108333333333333]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.7452441618992435, 'gamma': 2.4031644268654944, 'learning_rate': 0.47475907015514823, 'max_depth': 4.0, 'min_child_weight': 7.0, 'reg_alpha': 125.0, 'reg_lambda': 0.34339435319197786}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdc212fb",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "best_hyperparams['objective'] = 'reg:squarederror'\n",
    "# xgb_reg = xgb.XGBRegressor(best_hyperparams, objective='reg:squarederror')\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "pred = xgb_reg.predictt(X_train_, y_train_,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "print(accuracy_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157d55f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                \n",
      "0.8161666666666667                                    \n",
      "SCORE:                                                                           \n",
      "0.8176666666666667                                                               \n",
      "SCORE:                                                                           \n",
      "0.8171666666666667                                                               \n",
      "SCORE:                                                                           \n",
      "0.8165                                                                           \n",
      "SCORE:                                                                           \n",
      "0.8153333333333334                                                               \n",
      "SCORE:                                                                           \n",
      "0.7968333333333333                                                               \n",
      "SCORE:                                                                           \n",
      "0.8141666666666667                                                               \n",
      "SCORE:                                                                           \n",
      "0.818                                                                            \n",
      "SCORE:                                                                           \n",
      "0.8163333333333334                                                  \n",
      "SCORE:                                                              \n",
      "0.817                                                               \n",
      "SCORE:                                                               \n",
      "0.8175                                                               \n",
      "SCORE:                                                               \n",
      "0.8171666666666667                                                   \n",
      "SCORE:                                                               \n",
      "0.8118333333333333                                                   \n",
      "SCORE:                                                               \n",
      "0.817                                                                \n",
      "SCORE:                                                               \n",
      "0.8146666666666667                                                   \n",
      "SCORE:                                                               \n",
      "0.8163333333333334                                                   \n",
      "SCORE:                                                               \n",
      "0.8138333333333333                                                   \n",
      "SCORE:                                                               \n",
      "0.8116666666666666                                                   \n",
      " 45%|████▌     | 18/40 [01:04<00:43,  1.97s/trial, best loss: -0.818]"
     ]
    }
   ],
   "source": [
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_ada,\n",
    "                        space = space_ada,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 40,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd22aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_log,\n",
    "                        space = space_log,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e87f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective_svm,\n",
    "                        space = space_svm,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_value = 1\n",
    "for param_name in best_hyperparams:\n",
    "    print(f'{param_name}={param_value}')\n",
    "# space_svm[best_hyperparams]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d46d9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_test1 = method0.transform(X_test)\n",
    "X_test1 = pd.DataFrame(X_test1, columns=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3afe",
   "metadata": {},
   "source": [
    "## Performance at given percentages\n",
    "### robustness\n",
    "\n",
    "As opposed to simply classifiying clients as expected to default vs not-expected to default, quantifying is more meaningful. I.e. defining a probability of default has more potential.\n",
    "\n",
    "To estimate the real probability, the Smooth Sorting Method can be used, which estimates the real probability by looking at neighboring points and taking the mean of these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbabd6",
   "metadata": {},
   "source": [
    "__Smooth Sorting Method__ from the original paper (Yeh, I. C., & Lien, C. H. (2009)): \n",
    "\n",
    "$$\\text{P}_i = \\frac{\\sum_{j=-n}^{n}\\text{Y}_{i-j}}{2n+1}$$\n",
    "\n",
    "where $\\text{P}_i$ is the estimated real probability of default, $\\text{Y}_{i}$ is the binary variable of default (1) or non-default (0), $n$ is the number of data for smoothing.<br>\n",
    "The Smooth Sorting Method is used on sorted data, from the lowest probability of default occuring to the highest probability of default occuring. \n",
    "\n",
    "This is interesting to look at because loaners adopt different risk strategies.    \n",
    "(for this we "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec14761",
   "metadata": {},
   "source": [
    "we have the lists : `y_predicted` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9551f14",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(eta=0.3, gamma=0.5, use_label_encoder=False)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_predicted = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737b8f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709565ee",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(y_predicted)\n",
    "\n",
    "y_test_sorted = y_test_numpy[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51a798",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_test_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d2765",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_avg = []\n",
    "n = 200\n",
    "for counter in range(n,len(y_test_sorted)-n):\n",
    "    intermediate_val = np.mean(y_test_sorted[counter-n:counter+n])\n",
    "    y_avg.append(intermediate_val)\n",
    "    \n",
    "y_predicted_sorted = sorted(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4507880",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(y_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76cfdd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(sorted(y_predicted[n:len(y_predicted)-n]),y_avg)\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8638e2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.shape(y_predicted[n:len(y_predicted)-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee291ce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sorted(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67e43",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbedc5b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_selected = y_predicted[n:len(y_predicted)-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6610a5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_avg,y_predicted_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c73b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(y_predicted)-n\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CW2)",
   "language": "python",
   "name": "pycharm-1482e948"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}